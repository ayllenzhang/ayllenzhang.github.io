<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ayllen&#39;s Neverland</title>
  
  
  <link href="https://ayllenzhang.github.io/atom.xml" rel="self"/>
  
  <link href="https://ayllenzhang.github.io/"/>
  <updated>2021-06-19T18:00:47.178Z</updated>
  <id>https://ayllenzhang.github.io/</id>
  
  <author>
    <name>Ayllen Zhang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>摇曳露营的巡礼之旅，富士山行记</title>
    <link href="https://ayllenzhang.github.io/2019/08/fuji-mnt/"/>
    <id>https://ayllenzhang.github.io/2019/08/fuji-mnt/</id>
    <published>2019-08-17T18:06:10.000Z</published>
    <updated>2021-06-19T18:00:47.178Z</updated>
    
    <content type="html"><![CDATA[<p>时隔数月的回忆篇。（2021年注: 文中 b 站视频已失效，之后重传）</p><p><escape><span id="more"></span></escape></p><hr /><p>日本之行的第 5 天，在新宿站换好了 JR PASS ，就准备前往富士山了。</p><p>最初的打算是乘坐大巴（JR 所属的 JR Bus 是可以用 PASS 的），但到了与新宿站一条马路之隔的汽车站才发现当日的票已经卖完了，看来下次想乘巴士还得预定。查询车次后，选了如下的路线：</p><figure><img src="https://i.loli.net/2021/06/19/4rfYb5enuQtkTKq.png" alt="fuji_route.png" /><figcaption aria-hidden="true">fuji_route.png</figcaption></figure><p>将大行李存在新宿，只留下有着大部分露营用具的登山包和装着食材的咩姐袋子就出发了。</p><figure><img src="https://i.loli.net/2021/06/19/oeRh5yQtPZWqF3c.jpg" alt="on_azusa.jpg" /><figcaption aria-hidden="true">on_azusa.jpg</figcaption></figure><p>列车周边的景物一开始还是很东京的</p><figure><img src="https://i.loli.net/2021/06/18/a6kiuHQFsZlPSVo.jpg" alt="azusa_city.jpg" /><figcaption aria-hidden="true">azusa_city.jpg</figcaption></figure><p>没过多久就变成了山区景色</p><figure><img src="https://i.loli.net/2021/06/18/hvgsAYCuQ59IR7f.jpg" alt="azusa_country.jpg" /><figcaption aria-hidden="true">azusa_country.jpg</figcaption></figure><p>快到甲府的时候，能看到富士山的小脑袋了</p><figure><img src="https://i.loli.net/2021/06/18/wm1LAJcMkUs4H9x.jpg" alt="azusa_little_fuji.jpg" /><figcaption aria-hidden="true">azusa_little_fuji.jpg</figcaption></figure><p>到甲府后，换乘了长这样的身延线。明明没什么人嘛，为什么大巴没票了...</p><figure><img src="https://i.loli.net/2021/06/19/JbqYtawI9k4SjPU.jpg" alt="shenyan.jpg" /><figcaption aria-hidden="true">shenyan.jpg</figcaption></figure><p>富士山以肉眼可见的速度变大</p><figure><img src="https://i.loli.net/2021/06/18/QtXj9JMU4iYzEk2.jpg" alt="big_fuji.jpg" /><figcaption aria-hidden="true">big_fuji.jpg</figcaption></figure><p>到了富士宫站以后才发现 14:13 出发的 已经是当日最后一趟巴士了。虽然之前已经在网上了解到这边巴士线路很少但没想到少到了这个地步，怪不得大多数巡礼党都是选择自驾前来。</p><figure><img src="https://i.loli.net/2021/06/19/X69PQOeU4x3s2RI.png" alt="fujibus_timetable.png" /><figcaption aria-hidden="true">fujibus_timetable.png</figcaption></figure><p>在富士急行巴士上又拍了一段，果然富士山就是好看啊</p><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;"><p><iframe src="//player.bilibili.com/player.html?aid=64302824&cid=111745013&page=3&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position:absolute; width:100%; height:100%; left:0; top:0;"> </iframe></p><p>然后在「朝霧グリーンパーク」这个站下了车。从巴士站到露营地还要走个两公里的样子，而且是朝着富士山的反方向走，导致我一路上都在怀疑自己是否走错了。</p><figure><img src="https://i.loli.net/2021/06/18/VImfNBxu4PMi9T3.png" alt="asagiri_to_camp.png" /><figcaption aria-hidden="true">asagiri_to_camp.png</figcaption></figure><p>然后一边走一边看身后的富士山，哈哈</p><figure><img src="https://i.loli.net/2021/06/18/rSObBvJgpozyqlL.jpg" alt="campsite_road.jpg" /><figcaption aria-hidden="true">campsite_road.jpg</figcaption></figure><p>终于走到了！</p><figure><img src="https://i.loli.net/2021/06/18/GE47Ic61yVnPLM2.jpg" alt="camp_site_frontdoor.jpg" /><figcaption aria-hidden="true">camp_site_frontdoor.jpg</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/tXkI2TbYKUZidnV.jpg" alt="front_door_anime.jpg" /><figcaption aria-hidden="true">front_door_anime.jpg</figcaption></figure><p>这次去的是 <a href="https://fumotoppara.net/facilities">ふもとっぱら</a> 这个营地，对应摇曳露营的第 2 ~ 3 话。官网上是可以预约营地和住宿的，但是我并没有日本手机号就没有预约。由于是四月去的，也还没到旺季，所以当天去当天办理也完全可以。办完手续会给一张地图，和动画中的一模一样。顺带一提官网是有这个地图的<a href="https://fumotoppara.net/wp-content/uploads/map_map2015.jpg">电子版</a>的。</p><figure><img src="https://i.loli.net/2021/06/19/qzaReSg841LyY2t.png" alt="fummoto_map.png" /><figcaption aria-hidden="true">fummoto_map.png</figcaption></figure><p>这里就是营地的办公室了，交钱领地图都在这儿，也是和动画中的一毛一样</p><figure><img src="https://i.loli.net/2021/06/19/qayd2g375DC4Kji.jpg" alt="yewuguanli_real.jpg" /><figcaption aria-hidden="true">yewuguanli_real.jpg</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/BlAsUzZfoE5VK1Q.png" alt="yewuguanli.png" /><figcaption aria-hidden="true">yewuguanli.png</figcaption></figure><p>自带帐篷也需要 2000 日元的使用费，相当于国内三线城市睡一晚了</p><figure><img src="https://i.loli.net/2021/06/18/PtDMwReIT78xmBc.png" alt="2000yen.png" /><figcaption aria-hidden="true">2000yen.png</figcaption></figure><p>開放感すげえ...</p><figure><img src="https://i.loli.net/2021/06/19/wlfhPzq4eCkLKpI.png" alt="kaihou.png" /><figcaption aria-hidden="true">kaihou.png</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/qbeyHNngUlak6Vt.jpg" alt="kaihou_real.jpg" /><figcaption aria-hidden="true">kaihou_real.jpg</figcaption></figure><p>当然人多的时候是这样的</p><figure><img src="https://i.loli.net/2021/06/19/KiBkygm5PM4ZxWo.jpg" alt="renduo.jpg" /><figcaption aria-hidden="true">renduo.jpg</figcaption></figure><p>挑了块平整无水坑的草坪就开始扎营啦</p><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;"><iframe src="//player.bilibili.com/player.html?aid=64302824&cid=111646349&page=1&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position:absolute; width:100%; height:100%; left:0; top:0;"> </iframe></div><p>顶着大风搭好了帐篷。大风天别说单人扎营，上次在百花山三人扎一个都难。可算完工了。</p><figure><img src="https://i.loli.net/2021/06/19/K6NXfbaorJE8VzZ.jpg" alt="wangong.jpg" /><figcaption aria-hidden="true">wangong.jpg</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/wrEq3uXB4JSshid.png" alt="yoshi.png" /><figcaption aria-hidden="true">yoshi.png</figcaption></figure><p>Solo camp 真是太棒了！</p><p>不过一路过来加上搭帐篷已经是又累又饿，是时候开饭了</p><figure><img src="https://i.loli.net/2021/06/19/o5ZlCvrgJ2t7UYy.jpg" alt="kaifan.jpg" /><figcaption aria-hidden="true">kaifan.jpg</figcaption></figure><figure><img src="https://i.loli.net/2021/06/18/O2qCoZK9XlTVw4P.png" alt="burner.png" /><figcaption aria-hidden="true">burner.png</figcaption></figure><p>果然最好完成的露营美味就是火锅了呀。</p><figure><img src="https://i.loli.net/2021/06/19/bCKty7xQApoehdG.png" alt="hotpot.png" /><figcaption aria-hidden="true">hotpot.png</figcaption></figure><p>吃好喝好之后，就准备绕着营地走两圈了。</p><p>Double 富士山！</p><figure><img src="https://i.loli.net/2021/06/19/I3vNbydX1E5TuL2.png" alt="twofuji.png" /><figcaption aria-hidden="true">twofuji.png</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/mvUZqFyOjtEkIBY.jpg" alt="two_mountain.jpg" /><figcaption aria-hidden="true">two_mountain.jpg</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/u9doxpflRcvYSZO.png" alt="twofujisample.png" /><figcaption aria-hidden="true">twofujisample.png</figcaption></figure><p>这边的红房子据说以前是存放谷物的，不过现在已经只是洗手间了</p><figure><img src="https://i.loli.net/2021/06/19/QuzEHOYgoPSwRke.jpg" alt="redhouse_real.jpg" /><figcaption aria-hidden="true">redhouse_real.jpg</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/VlWbmt5618XHJFY.png" alt="redhouse.png" /><figcaption aria-hidden="true">redhouse.png</figcaption></figure><p>红房子的侧面是一张大脸</p><figure><img src="https://i.loli.net/2021/06/18/EaIG9SeJyq6PRMc.jpg" alt="dalian_real.jpg" /><figcaption aria-hidden="true">dalian_real.jpg</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/CsNjrchif9nUtFX.png" alt="dalian_anime.png" /><figcaption aria-hidden="true">dalian_anime.png</figcaption></figure><p>林子里的动物雕像，嗷呜~</p><figure><img src="https://i.loli.net/2021/06/18/rDWHGIUkQxeNEm7.jpg" alt="aowu_real.jpg" /><figcaption aria-hidden="true">aowu_real.jpg</figcaption></figure><figure><img src="https://i.loli.net/2021/06/18/n5pRGJceAXH6VsQ.png" alt="aowu_anime.png" /><figcaption aria-hidden="true">aowu_anime.png</figcaption></figure><figure><img src="https://i.loli.net/2021/06/18/DB5JnCHlV1ISELs.png" alt="aowu.png" /><figcaption aria-hidden="true">aowu.png</figcaption></figure><p>上面这几个地方的位置关系大概这样，狮虎雕像和办公室则要在更后方</p><figure><img src="https://i.loli.net/2021/06/19/9EKtSQlmznxd2iu.png" alt="position.png" /><figcaption aria-hidden="true">position.png</figcaption></figure><p>没转多久太阳也就快落山了，不过今天并没有晚霞，只是一般般的红色</p><figure><img src="https://i.loli.net/2021/06/19/NmEKRJotWdrvCfB.png" alt="pink.png" /><figcaption aria-hidden="true">pink.png</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/GVdt8Jsc6QkYWKo.jpg" alt="pinkornot.jpg" /><figcaption aria-hidden="true">pinkornot.jpg</figcaption></figure><p>逐渐天黑了，大家都点起了帐篷里的小灯</p><figure><img src="https://i.loli.net/2021/06/19/sdryCxnP2cpHBOQ.jpg" alt="tonight.jpg" /><figcaption aria-hidden="true">tonight.jpg</figcaption></figure><p>由于天黑以后实在是无聊，八点多就睡了，准备四点起来看日出。睡前拍了个帐篷。</p><figure><img src="https://i.loli.net/2021/06/19/q7gdaCZLwAcyP62.jpg" alt="shuiqm.jpg" /><figcaption aria-hidden="true">shuiqm.jpg</figcaption></figure><p>刚醒的时候天还完全没亮</p><figure><img src="https://i.loli.net/2021/06/19/JswcxSOgN1TZ4UB.jpg" alt="gangxing.jpg" /><figcaption aria-hidden="true">gangxing.jpg</figcaption></figure><p>慢慢地稍微亮了一点点</p><figure><img src="https://i.loli.net/2021/06/19/yJ7vpWHENZYR6gn.jpg" alt="shaoliang.jpg" /><figcaption aria-hidden="true">shaoliang.jpg</figcaption></figure><p>把 pocket 放着拍日出了，我在旁边玩手机坐等</p><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;"><iframe src="//player.bilibili.com/player.html?aid=64302824&cid=111648285&page=2&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position:absolute; width:100%; height:100%; left:0; top:0;"> </iframe></div><p>由于三脚架坏了只能放在炉头的盒子上拍，所以下面有个橙色盖子 2333。</p><p>我自己也用手机拍了两张。</p><figure><img src="https://i.loli.net/2021/06/19/Wz1yo46XdKUROCe.jpg" alt="morning1.jpg" /><figcaption aria-hidden="true">morning1.jpg</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/zcfQtKNV8GyHYEm.jpg" alt="morning2.jpg" /><figcaption aria-hidden="true">morning2.jpg</figcaption></figure><p>太阳刚出的时候地面会有一层雾，挺漂亮的。</p><p>去确认了食堂，然后发现食堂内部在装修中，也就没得吃了。</p><figure><img src="https://i.loli.net/2021/06/19/5rXK8qgds3vy7MC.jpg" alt="shitang_real.jpg" /><figcaption aria-hidden="true">shitang_real.jpg</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/vV6QINWngzRD2CU.png" alt="shitang.png" /><figcaption aria-hidden="true">shitang.png</figcaption></figure><p>只能再来一锅火锅了。由于早上太冷+风大在帐篷外根本煮不熟只好在帐篷里完成了。</p><figure><img src="https://i.loli.net/2021/06/19/ezymHt7acJMuoBZ.jpg" alt="jungu.jpg" /><figcaption aria-hidden="true">jungu.jpg</figcaption></figure><p>这次是菌菇锅底。</p><p>之后就去办离场手续了。路上看见了供游客用餐的简易木屋，屋前的大树很漂亮。</p><figure><img src="https://i.loli.net/2021/06/19/hl2rCyc54XZYdof.jpg" alt="xiaocanting_real.jpg" /><figcaption aria-hidden="true">xiaocanting_real.jpg</figcaption></figure><p>里面大概是这样的：</p><figure><img src="https://i.loli.net/2021/06/19/tGmSlWToPVvs9ON.png" alt="xiaocanting.png" /><figcaption aria-hidden="true">xiaocanting.png</figcaption></figure><p>这才注意到还有个小纪念品，动画里也提到了这两条小狗。</p><p><img src="https://i.loli.net/2021/06/19/3xM9HsPWv1lK4ch.jpg" alt="two_dog.jpg" /><img src="https://i.loli.net/2021/06/19/c9gVmqnwWlSCajI.png" alt="dog1.png" /></p><figure><img src="https://i.loli.net/2021/06/19/RzlEwrneLCkImh8.png" alt="dog2.png" /><figcaption aria-hidden="true">dog2.png</figcaption></figure><p>溜啦溜啦</p><figure><img src="https://i.loli.net/2021/06/19/COMlv9isqFaHwuG.jpg" alt="sayonara.jpg" /><figcaption aria-hidden="true">sayonara.jpg</figcaption></figure><p>出发去另一个露营地了，第一集中的浩庵露营场。</p><p>刚下车就看见了抚子睡的地方</p><figure><img src="https://i.loli.net/2021/06/19/UNwPT2yZ4M8nH5C.jpg" alt="gangxiache.jpg" /><figcaption aria-hidden="true">gangxiache.jpg</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/GDaqSRfEN1knmWM.png" alt="shuijiao.png" /><figcaption aria-hidden="true">shuijiao.png</figcaption></figure><p>然后正前方就是浩庵露营场的前台和商店所在建筑了</p><figure><img src="https://i.loli.net/2021/06/19/P5It3Z8yJVQigz9.jpg" alt="koan_real.jpg" /><figcaption aria-hidden="true">koan_real.jpg</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/AgtTJpimGEbUHcO.png" alt="koan_anime.png" /><figcaption aria-hidden="true">koan_anime.png</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/jXlJZ8vOt2ube4s.jpg" alt="shoufu.jpg" /><figcaption aria-hidden="true">shoufu.jpg</figcaption></figure><p>相对于麓露营场，这边的设施要完善多了，也有很多食材和露营用具可购买。凛还感叹过麓露营场</p><figure><img src="https://i.loli.net/2021/06/19/mLOYc189oi6sxlu.png" alt="noshop.png" /><figcaption aria-hidden="true">noshop.png</figcaption></figure><p>这边有不少的露营周边卖，甚至可以微信支付</p><figure><img src="https://i.loli.net/2021/06/20/ukFPlgfMz8Wc4GA.jpg" alt="XguvbILV5taqEGz.jpg" /><figcaption aria-hidden="true">XguvbILV5taqEGz.jpg</figcaption></figure><p>因为露营场只有露营的人才能进去，我就只是在路边转了转。</p><figure><img src="https://i.loli.net/2021/06/19/dwRv49XpAb6qGrZ.jpg" alt="chaiho.jpg" /><figcaption aria-hidden="true">chaiho.jpg</figcaption></figure><p>商店提供木柴，但林子里也是可以自己捡柴的。</p><p>然后我买了两个芝麻凛的挂饰。</p><figure><img src="https://i.loli.net/2021/06/19/SjfdH3RuVQXNl8k.jpg" alt="guashi.jpg" /><figcaption aria-hidden="true">guashi.jpg</figcaption></figure><p>开了两个扭蛋刚好是双女主，算是欧了一把</p><figure><img src="https://i.loli.net/2021/06/19/qh5Br1ROcWuFwx6.jpg" alt="ouhuang.jpg" /><figcaption aria-hidden="true">ouhuang.jpg</figcaption></figure><p>景色真好啊，拍了张我的小登山包和大富士山</p><figure><img src="https://i.loli.net/2021/06/19/XA6RMgjfrlY8Ded.jpg" alt="langan2.jpg" /><figcaption aria-hidden="true">langan2.jpg</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/lT8qe6A7niUGhIQ.png" alt="langan.png" /><figcaption aria-hidden="true">langan.png</figcaption></figure><p>最后一站是甲斐常叶，摇曳露营设定中学校所在的地方。站前有条浅溪。</p><figure><img src="https://i.loli.net/2021/06/19/qvzoBtG7c8KfV4s.jpg" alt="zhanqianhe.jpg" /><figcaption aria-hidden="true">zhanqianhe.jpg</figcaption></figure><p>溪对面有药店，咖啡店和杂货铺，也有很多周边卖。</p><figure><img src="https://i.loli.net/2021/06/19/mYfRti6Nol3KvuS.jpg" alt="zhanqian_anime.jpg" /><figcaption aria-hidden="true">zhanqian_anime.jpg</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/nl2XMboaPfVir4E.jpg" alt="zhanqian.jpg" /><figcaption aria-hidden="true">zhanqian.jpg</figcaption></figure><p>第八集出现过桥对侧的视角，我中午就是在下图右侧的店里吃了盒方便面打发了。</p><figure><img src="https://i.loli.net/2021/06/19/4GaYkLwDXTM6lFs.png" alt="dvce.png" /><figcaption aria-hidden="true">dvce.png</figcaption></figure><p>左边山上就是学校，不过现实中已经废校了，农村人口减少的问题日本也存在啊。</p><figure><img src="https://i.loli.net/2021/06/19/cXUtrQneNY1kPWS.jpg" alt="jiafeimount.jpg" /><figcaption aria-hidden="true">jiafeimount.jpg</figcaption></figure><p>废校了也不确定能否进去，便只是远眺了一些。甲斐常叶这个小站在动画中也出现过</p><figure><img src="https://i.loli.net/2021/06/19/V3smpBoJZOlCUPe.jpg" alt="xiaozhan.jpg" /><figcaption aria-hidden="true">xiaozhan.jpg</figcaption></figure><figure><img src="https://i.loli.net/2021/06/19/Rm2ksFBJVnxoOTI.png" alt="xiaozhan_anime.png" /><figcaption aria-hidden="true">xiaozhan_anime.png</figcaption></figure><p>车来了，也意味着告别这次短暂的巡礼之旅了。等露营二期出了再来多巡礼一些地方吧！</p><figure><img src="https://i.loli.net/2021/06/19/LgQ67rlzXuqyhZn.jpg" alt="chelaile.jpg" /><figcaption aria-hidden="true">chelaile.jpg</figcaption></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;时隔数月的回忆篇。（2021年注: 文中 b 站视频已失效，之后重传）&lt;/p&gt;
&lt;p&gt;&lt;escape&gt;</summary>
    
    
    
    <category term="远方 / Travel" scheme="https://ayllenzhang.github.io/categories/Travel/"/>
    
    
    <category term="Japan" scheme="https://ayllenzhang.github.io/tags/Japan/"/>
    
    <category term="Fuji" scheme="https://ayllenzhang.github.io/tags/Fuji/"/>
    
  </entry>
  
  <entry>
    <title>Notes about MCMC and Sampling</title>
    <link href="https://ayllenzhang.github.io/2019/07/mcmc-notes/"/>
    <id>https://ayllenzhang.github.io/2019/07/mcmc-notes/</id>
    <published>2019-07-26T11:43:46.000Z</published>
    <updated>2021-06-19T17:54:14.888Z</updated>
    
    <content type="html"><![CDATA[<p>It all starts with a question:</p><blockquote><p>How to sample from a given distribution?</p></blockquote><p><escape><span id="more"></span></escape></p><h1 id="the-simplest-method">The simplest method</h1><p>Let's say, how to sample from <span class="math inline">\(Uniform(0, 1)\)</span>?</p><p>Actually the <code>random()</code> function, which is a pseudo-random number generator, have already solved the problem for us. It can generate a sequence of numbers whose properties approximate the properties of sequences of random numbers obeying uniform distribution.</p><p>Moreover, we can sample from normal distribution by utilizing <em>Box-Muller</em> transform.</p><blockquote><p><strong>Box-Muller transform</strong></p><p>If random variables <span class="math inline">\(U_1, U_2 \overset{\text{iid}}{\sim} U(0,1)\)</span>, and</p><p><span class="math display">\[\begin{align} Z_1=\sqrt{-2\ln{U_1}}cos(2\pi U_2) \\ Z_2=\sqrt{-2\ln{U_1}}sin(2\pi U_2) \end{align}\]</span></p><p>then <span class="math inline">\(N_1, N_2 \overset{\text{iid}}{\sim} \mathcal{N}(0,1)\)</span></p></blockquote><p>Some other common continuous distribution e.g. exponential distribution, gamma distribution, beta distribution and t-distribution could also be sampling with similar math transform. However, when sampling from more complicated distributions or high dimensional distributions, it's not so easy to find such a transform. Here, complex sampling method will be used, and the algorithms we're going to introduce, MCMC(Markov Chain Monte Carlo) and Gibbs sampling are two of them that are commonly used.</p><h1 id="some-other-methods">Some other methods</h1><p>Before looking directly at our goals, I'd like to introduce some other sampling methods first.</p><h2 id="rejection-sampling">Rejection sampling</h2><p>Also called accept-reject method. Given a distribution with p.d.f. <span class="math inline">\(p(x)\)</span>. Suppose there is another simple distribution function <span class="math inline">\(q(x)\)</span> from which we can sample easily. If there exist a constant <span class="math inline">\(M&lt;\inf\)</span> that for all <span class="math inline">\(x\in\mathbb{R}\)</span>,</p><p><span class="math display">\[p(x)\leq Mq(x)\]</span></p><p>then we can sample from <span class="math inline">\(p(x)\)</span> with the following method:</p><div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="op">=</span> <span class="dv">1</span> to N:</span><span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    Generate u <span class="op">~</span> U(<span class="dv">0</span>, <span class="dv">1</span>) <span class="kw">and</span> x <span class="op">~</span> q(x)</span><span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> u <span class="op">&lt;</span> p(x) <span class="op">/</span> (M <span class="op">*</span> q(x)):</span><span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        x <span class="kw">is</span> accepted <span class="im">as</span> a sample</span><span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>        i <span class="op">+=</span> <span class="dv">1</span></span><span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span><span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span></code></pre></div><p>It can be easily proved that this algorithm works.</p><h2 id="importance-sampling">Importance Sampling</h2><p>Say if we want to know the expectation of <span class="math inline">\(f(x)\)</span>, i.e. <span class="math inline">\(\operatorname{E}[f(x)]\)</span>, in which the random variable <span class="math inline">\(x\)</span> follows a distribution <span class="math inline">\(p(x)\)</span>. Also, consider another simple distribution function <span class="math inline">\(q(x)\)</span> that can be easily sampled. Then</p><p><span class="math display">\[ \hat{E}=\int_x{f(x)p(x)dx}=\int_x{f(x)\frac{p(x)}{q(x)}q(x)dx}\]</span></p><p>Let <span class="math inline">\(w(x)=\frac{p(x)}{q(x)}\)</span>, the last formula can be seen as <span class="math inline">\(\operatorname{E}[f(x)w(x)]\)</span> in which <span class="math inline">\(x\sim q(x)\)</span>. As we can easily sample from <span class="math inline">\(q(x)\)</span>,</p><p><span class="math display">\[\hat{E}=\frac{1}{N}\sum\limits_{i=1}^N{f(x^{(i)})w(x^{(i)})}\]</span></p><p>in which <span class="math inline">\(x^{(i)}\)</span> is the <span class="math inline">\(i\)</span>-th sampled <span class="math inline">\(x\)</span> from <span class="math inline">\(q(x)\)</span>. Here <span class="math inline">\(w(x)\)</span> is called <strong>importance weight</strong>.</p><h1 id="markov-chain-monte-carlo">Markov chain Monte Carlo</h1><p>MCMC methods comprise a class of algorithms for sampling from a probability distribution. bMarkov Process, Markov Chain &amp; Hidden Markov Model</p><h3 id="markov-process">Markov process</h3><p>Markov process is a stochastic <em>process</em> that satisfies the Markov property, i.e. the conditional probability distribution of future states of the process depends only upon the present state.</p><h3 id="markov-chain">Markov chain</h3><p>Markov chain is a stochastic <em>model</em> describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.</p><p>For a Markov chain with finite state space, the transition probability distribution can be represented by a matrix, called the transition matrix, with the <span class="math inline">\((i, j)th\)</span> element of <span class="math inline">\(P\)</span> equals to <span class="math display">\[p_{ij}=\Pr(X_{n+1}=j\mid X_{n}=i)\]</span> A Markov chain is called time-homogeneous if the transition matrix <span class="math inline">\(P\)</span> is the same after each step.</p><p>If the Markov chain is irreducible and aperiodic, then there is a unique stationary distribution <strong>π</strong>. <span class="math display">\[\pi\mathbf{P}=\pi\]</span> There are three several important properties for those fully connected (namely for all <span class="math inline">\((i,j)\)</span> in <span class="math inline">\(P\)</span>, <span class="math inline">\(\exists n\in\mathbb{N^+} \text{ such that }P^n_{ij}\neq0\)</span>), aperiodic, time-homogeneous Markov chain.</p><ol type="1"><li><p><span class="math display">\[\begin{equation}\lim_{n\rightarrow \infty}{P^n}=\begin{bmatrix} \pi\\\pi\\\vdots\\\pi\\ \end{bmatrix}= \begin{bmatrix}\pi(1)&amp;\pi(2)&amp;\cdots&amp;\pi(j)&amp;\cdots\\\pi(1)&amp;\pi(2)&amp;\cdots&amp;\pi(j)&amp;\cdots\\\vdots&amp;\vdots&amp;\ddots&amp;\pi(j)&amp;\cdots\\\pi(1)&amp;\pi(2)&amp;\cdots&amp;\pi(j)&amp;\cdots\\\vdots&amp;\vdots&amp;\vdots&amp;\vdots&amp;\vdots\\\end{bmatrix}\end{equation}\]</span></p></li><li><p><span class="math display">\[\pi(j)=\sum_{i=0}^{\infty}\pi(i)P_{ij}\]</span></p></li><li><p><span class="math inline">\(\pi\)</span> is the only non-negative solution of equation <span class="math inline">\(\pi\mathbf{P}=\pi\)</span></p></li></ol><h3 id="detailed-balance-condition">Detailed balance condition</h3><p>A Markov chain is said to be reversible if there is a probability distribution <span class="math inline">\(\pi\)</span> over its states such that <span class="math display">\[\pi _{i}\Pr(X_{n+1}=j\mid X_{n}=i)=\pi _{j}\Pr(X_{n+1}=i\mid X_{n}=j)\]</span> the detailed balance equation can be written as <span class="math display">\[\pi _{i}p_{ij}=\pi _{j}p_{ji}\,\]</span></p><p>which indicates that, for each pair of states <span class="math inline">\((i, j)\)</span>, the probability mass gained from each other should be equal to the probability mass they loss at the same time, when the stationary distribution <span class="math inline">\(\pi\)</span> is reached.</p><h3 id="hidden-markov-model">Hidden Markov Model</h3><p>HMM is a statistical Markov model in which the system being modeled is assumed to be a Markov process with hidden states and visible output state for each hidden state. The following image describes a Markov chain. <span class="math inline">\(x(t-1)\)</span>, <span class="math inline">\(x(t)\)</span> and <span class="math inline">\(x(t+1)\)</span> denote the hidden states at the 3 moment, while <span class="math inline">\(y(t-1)\)</span>, <span class="math inline">\(y(t)\)</span> and <span class="math inline">\(y(t+1)\)</span> denote the corresponding observer states.</p><figure><img src="https://i.loli.net/2021/06/19/j7xyLaiEI86NOe1.png" alt="HMM.png" /><figcaption aria-hidden="true">HMM.png</figcaption></figure><h2 id="metropolishastings-algorithm">Metropolis–Hastings algorithm</h2><p><strong>M-H algorithm</strong> is one of the commonly used random walk Monte Carlo methods. In fact, the name Monte Carlo is suggested to use by Metropolis. As said above, MCMC is to construct a Markov chain with stationary distribution <span class="math inline">\(\pi=p(x)\)</span>, in which <span class="math inline">\(p(x)\)</span> is the given distribution to be sampled.</p><p>Consider that we already know the given distribution <span class="math inline">\(p(x)\)</span> and its transition matrix <span class="math inline">\(Q\)</span>. Generally we'll have <span class="math display">\[p(i)q(i,j)\neq p(j)q(j,i)\]</span> We can introduce another coefficient <span class="math inline">\(\alpha(i,j)\)</span> that will hopefully solve the problem for us, namely <span class="math display">\[\begin{equation}p(i)q(i,j)\alpha(i,j)=p(j)q(j,i)\alpha(j,i) \tag{*}\end{equation}\]</span> Clearly we can let <span class="math inline">\(\alpha(i,j)=p(j)q(j,i)\)</span> to make the equation true. If we let <span class="math inline">\(q&#39;(i,j)=q(i,j)\alpha(i,j)\)</span>, the original equation would become: <span class="math display">\[p(i)q&#39;(i,j)=p(j)q&#39;(j,i)\]</span> Now we have successfully constructed a Markov chain with transition matrix <span class="math inline">\(q&#39;\)</span> and given stationary distribution <span class="math inline">\(p(x)\)</span>. The Metropolis–Hastings algorithm is described below. Notice that <span class="math inline">\(q(j|i) = q(i,j)\)</span>.</p><div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>x_&#123;<span class="dv">0</span>&#125; <span class="op">=</span> x0 <span class="co"># Initialization</span></span><span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="op">=</span> <span class="dv">1</span> to N:</span><span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    Generate x<span class="op">*</span> <span class="op">~</span> q(x<span class="op">*|</span>x_&#123;i<span class="op">-</span><span class="dv">1</span>&#125;)</span><span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> <span class="bu">min</span>( <span class="dv">1</span>, ( p(x<span class="op">*</span>) <span class="op">*</span> q(x<span class="op">*|</span>x_&#123;i<span class="op">-</span><span class="dv">1</span>&#125;) ) <span class="op">/</span> ( p(x_&#123;i<span class="op">-</span><span class="dv">1</span>&#125;) <span class="op">*</span> q(x_&#123;i<span class="op">-</span><span class="dv">1</span>&#125;<span class="op">|</span>x<span class="op">*</span>) ) )</span><span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    Generate u <span class="op">~</span> U(<span class="dv">0</span>, <span class="dv">1</span>)</span><span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> u <span class="op">&gt;</span> a:</span><span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        x_&#123;i&#125; <span class="op">=</span> x_&#123;i<span class="op">-</span><span class="dv">1</span>&#125; <span class="co"># Reject</span></span><span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span><span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        x_&#123;i&#125; <span class="op">=</span> x<span class="op">*</span> <span class="co"># Accept</span></span></code></pre></div><p>When <span class="math inline">\(q(i, j)=q(j,i)\)</span> is satisfied, the algorithm is called <strong>Metropolis algorithm</strong>, in which</p><div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> <span class="bu">min</span>( <span class="dv">1</span>, p(x<span class="op">*</span>) <span class="op">/</span> p(x_&#123;i<span class="op">-</span><span class="dv">1</span>&#125;) )</span></code></pre></div><h2 id="gibbs-sampling">Gibbs Sampling</h2><p><strong>Gibbs sampling</strong> is a special case of the <em>Metropolis–Hastings algorithm</em>. Given a multivariate distribution, it's better for us to use <em>Gibbs sampling</em> if it is simpler to sample from a conditional distribution than to marginalize by integrating over a joint distribution. Suppose we want to obtain <span class="math inline">\(N\)</span> samples of <span class="math inline">\(\mathbf {X}=(x_{1},\dots ,x_{n})\)</span> from a joint distribution <span class="math inline">\({\displaystyle p(x_{1},\dots ,x_{n})}\)</span>. <em>Gibbs sampling</em> can be described as follows:</p><div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>X_0 <span class="op">=</span> X0 <span class="co"># Initialization</span></span><span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="op">=</span> <span class="dv">1</span> to N:</span><span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="op">=</span> <span class="dv">1</span> to n:</span><span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        sample x<span class="op">^</span>i_j <span class="im">from</span> the distribution:</span><span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>            p(x<span class="op">^</span>i_j<span class="op">|</span>x<span class="op">^</span>i_1,...,x<span class="op">^</span>i_&#123;j<span class="op">-</span><span class="dv">1</span>&#125;,x<span class="op">^</span>&#123;i<span class="op">-</span><span class="dv">1</span>&#125;_&#123;j<span class="op">+</span><span class="dv">1</span>&#125;,...x<span class="op">^</span>&#123;i<span class="op">-</span><span class="dv">1</span>&#125;_n)</span></code></pre></div><h2 id="slice-sampling">Slice Sampling</h2><p>Suppose you want to sample some random variable <span class="math inline">\(X\)</span> with distribution <span class="math inline">\(f(x)\)</span>. <em>Slice sampling</em> can be described as follows:</p><div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>x_0 <span class="op">=</span> x0 <span class="co"># Initialization</span></span><span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="op">=</span> <span class="dv">1</span> to N:</span><span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    Generate y_i <span class="im">from</span> U(<span class="dv">0</span>, x_&#123;i<span class="op">-</span><span class="dv">1</span>&#125;)</span><span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    Generate x<span class="op">*</span> <span class="im">from</span> U(Domain of x)</span><span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> f(x<span class="op">*</span>) <span class="op">&lt;</span> y</span><span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        generate x<span class="op">*</span> <span class="im">from</span> U(<span class="bu">min</span>(x_&#123;i<span class="op">-</span><span class="dv">1</span>&#125;, x<span class="op">*</span>), <span class="bu">max</span>(x_&#123;i<span class="op">+</span><span class="dv">1</span>&#125;, x<span class="op">*</span>))</span><span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    x_i <span class="op">=</span> x<span class="op">*</span></span></code></pre></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;It all starts with a question:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How to sample from a given distribution?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;escape&gt;</summary>
    
    
    
    <category term="科研 / Research" scheme="https://ayllenzhang.github.io/categories/Research/"/>
    
    
    <category term="Machine Learning" scheme="https://ayllenzhang.github.io/tags/Machine-Learning/"/>
    
    <category term="notes" scheme="https://ayllenzhang.github.io/tags/notes/"/>
    
    <category term="MCMC" scheme="https://ayllenzhang.github.io/tags/MCMC/"/>
    
  </entry>
  
  <entry>
    <title>Probability statistics notes</title>
    <link href="https://ayllenzhang.github.io/2019/07/proba-note/"/>
    <id>https://ayllenzhang.github.io/2019/07/proba-note/</id>
    <published>2019-07-24T11:31:19.000Z</published>
    <updated>2020-11-17T01:08:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>Some notes I took down last summer, when I was reviewing <em>statistics</em> and <em>probability</em>.</p><p><escape><span id="more"></span></escape></p><h2 id="basic-probability">Basic Probability</h2><h3 id="definitions">Definitions</h3><ul><li>Event: A set of outcomes of an experiment</li><li>Random variable: outcome of an experiment</li></ul><h3 id="bayes-theorem">Bayes' Theorem</h3><p>For two random events A, B <span class="math display">\[P(B|A)=\frac{P(AB)}{P(A)}=\frac{P(AB)}{P(B)}\cdot\frac{P(B)}{P(A)}=\frac{P(B)}{P(A)}\cdot P(A|B)\]</span> namely, <span class="math display">\[P(B|A)P(A)=P(AB)=P(A|B)P(B)\]</span></p><h3 id="independent-events">Independent events</h3><p>Events A and B are independent events if the occurrence of one of them does not affect the probability of the occurrence of the other. That is, two events are independent if either <span class="math display">\[P(B|A)=P(B)\]</span> or <span class="math display">\[P(A|B)=P(A)\]</span> Meanwhile, (A', B), (A, B'), (A', B') are also independent events if A, B are independent events.</p><h3 id="pmf-cdf-and-pdf">PMF, CDF and PDF</h3><ul><li><p><strong>PMF</strong> means probability mass function. Suppose that <span class="math inline">\(X: S → A (A \subseteq R\)</span>) is a discrete random variable defined on a sample space <span class="math inline">\(S\)</span>. Then the probability mass function <span class="math inline">\(f_X: A → [0, 1]\)</span> for <span class="math inline">\(X\)</span> is defined as <span class="math display">\[f_{X}(x)=\Pr(X=x)=P(\{s\in S:X(s)=x\})\]</span> <strong>Hyper geometric distribution</strong> is one of those common discrete distributions. If we randomly select n items without replacement from a set of N items of which:</p><ul><li>m of the items are of type-1</li><li>and N − m of the items are of type-2</li></ul><p>then the PMF of X, the discrete variable defined as the number of selected type-1 items, is called hyper-geometric distribution, which is: <span class="math display">\[P(X=x)=f(x)=\frac{\binom mx\binom {N\,-\,m}{n\,-\,x}}{\binom Nn}\]</span></p></li><li><p><strong>CDF</strong>, also called cumulative distribution function, is generally a function of a real-valued random variable <span class="math inline">\(X\)</span> given by <span class="math display">\[F_{X}(x)=\operatorname {P} (X\leq x)\]</span> The CDF of a continuous random variable <span class="math inline">\(X\)</span> can be expressed as the integral of its probability density function <span class="math inline">\(f_X\)</span> as follows: <span class="math display">\[F_{X}(x)=\int _{-\infty }^{x}f_{X}(t)\,dt\]</span></p></li><li><p><strong>PDF</strong>, known as probability density function, is similar with <strong>PMF</strong> while it's defined for continuous random variable. PDF is defined as follows. <span class="math display">\[\Pr[a\leq X\leq b]=\int _{a}^{b}f_{X}(x)\,dx.\]</span> Hence, if <span class="math inline">\(F_X\)</span> is the cumulative distribution function of continuous random variable <span class="math inline">\(X\)</span>, then: <span class="math display">\[F_{X}(x)=\int _{-\infty }^{x}f_{X}(u)\,du\]</span> namely, if <span class="math inline">\(f_X\)</span> is continuous at <span class="math inline">\(x\)</span>, <span class="math display">\[f_{X}(x)={\frac {d}{dx}}F_{X}(x)\]</span> <strong>uniform distribution</strong> is a common continuous distribution, in which the continuous random variable X has average probability in <span class="math inline">\([a, b]\)</span>, denoted as <span class="math inline">\(X\sim U(a, b)\)</span>. Its probability density function is <span class="math display">\[\]</span>f(x)=~~~(axb) $$</p></li></ul><h2 id="expectation-and-variance">Expectation and variance</h2><h3 id="expectation">Expectation</h3><p>For discrete variable <span class="math inline">\(X \in S\)</span>, expectation of <span class="math inline">\(x\)</span> is defined as: <span class="math display">\[E(X)=\sum_{x\in S}{x\cdot p(X=x)}\]</span> e.g. the expectation of hyper-geometric distribution can be calculated as follow: <span class="math display">\[\begin{align}E(X)&amp;=\sum_{x\in S}x\cdot\frac{\binom mx\binom {N\,-\,m}{n\,-\,x}}{\binom Nn} \\&amp;=\sum_{x\in S}\frac{\frac{m!}{(x-1)!(m-x)!}\binom {N\,-\,m}{n\,-\,x}}{\binom Nn} \\&amp;=\sum_{x\in S}\frac{m\cdot\binom{m-1}{x-1}\binom {N\,-\,m}{n\,-\,x}}{\binom Nn} \\&amp;=\sum_{x\in S}\frac{m\cdot\binom{N-1}{n-1}}{\binom Nn} \\&amp;=\frac{mn}{N}\end{align}\]</span> For continuous variable <span class="math inline">\(X\in \mathbb{R}\)</span>, expectation is defined as: <span class="math display">\[{E} [X]=\int _{\mathbb {R} }xf(x)\,dx\]</span> The expectation operator is linear in the sense that <span class="math display">\[E(aX+bY)=aE(X)+bE(Y)\]</span></p><h3 id="variance">Variance</h3><p>The variance of a random variable <span class="math inline">\(X\)</span> is the expected value of the squared deviation from the mean of <span class="math inline">\(X\)</span>. Let <span class="math inline">\(\mu = E[X]\)</span>, <span class="math display">\[\operatorname {Var}(X)=E\left[(X-\mu)^{2}\right]\\]</span> Substitute with <span class="math inline">\(\mu = E[x]\)</span>, we can have <span class="math display">\[\begin{align}\operatorname{Var}(X)&amp;=E\left[(X-E[X])^{2}\right]\\&amp;=E\left[X^2-2XE[X]+E[X]^2\right]\\&amp;=E[X^2]-2E[X]E[X]+E[X]^2 \\&amp;=E[X^2]-E[X]^2\end{align}\]</span> The variance of a sum of random variables and constants is given by <span class="math display">\[\operatorname {Var} (aX+bY+c)=a^{2}\operatorname {Var} (X)+b^{2}\operatorname {Var} (Y)+2ab\,\operatorname {Cov} (X,Y)\]</span> where <span class="math inline">\(\operatorname{Cov}(\cdot,\cdot)\)</span> is the covariance.</p><h3 id="covariance">Covariance</h3><p>The covariance between two jointly distributed real-valued random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is defined and transformed as: <span class="math display">\[\begin{align}\operatorname{Cov}(X, Y)&amp;=E[(X-E(X))(Y-E(Y)]\\&amp;=E[XY-XE(Y)-YE(X)+E(X)E(Y)]\\&amp;=E[XY]-E[X]E[Y]\end{align}\]</span> Note that <span class="math inline">\(\operatorname{Var}(X) = \operatorname{Cov}(X, X)\)</span>. Meanwhile, for random variables X, Y in joint support S, suppose <span class="math inline">\(f(x,y)\)</span> is the joint probability density function defined on <span class="math inline">\((x,y)\in S\)</span>.</p><p>For X and Y are discrete random variables, <span class="math display">\[\operatorname{Cov}(x,y)=\sum_{(x,y)\in S}(x-\mu_x)(y-\mu_y)f(x,y)\]</span> and for X and Y are continuous random variables, <span class="math display">\[\operatorname{Cov}(x,y)=\iint_{(x,y)\in S}(x-\mu_x)(y-\mu_y)f(x,y)dxdy\]</span></p><h3 id="correlation">Correlation</h3><p>The correlation is defined as: <span class="math display">\[\rho_{xy}=\operatorname{Corr}(X,Y)=\frac{\operatorname{Cov}(X,Y)}{\sigma_x\sigma_y}=\frac{\sigma_{xy}}{\sigma_x\sigma_y}\in[-1,1]\]</span> When <span class="math inline">\(\operatorname{Corr}(X,Y)\)</span> is close to <span class="math inline">\(\pm 1\)</span>, a strong linear relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is indicated.</p><h3 id="sample-expectation-and-variance">Sample expectation and variance</h3><p>Here we suppose <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, <span class="math inline">\(\dots\)</span> , <span class="math inline">\(X_n\)</span> are observations of a random sample of size n. Then</p><ul><li><span class="math inline">\(\bar{X}=\frac{1}{n}\sum_{i=1}^{n}{X_i}\)</span> is the sample mean of the n observations, and</li><li><span class="math inline">\(S^2=\frac{1}{n-1}\sum_{i=1}^{n}{(X_i-\bar{X})^2}\)</span> is the sample variance of the n observations</li></ul><p>Proof: Here we assume the original expectation(mean) and variance of <span class="math inline">\(X_i\)</span> to be <span class="math inline">\(\mu, \sigma^2\)</span>. Then we have: <span class="math display">\[E(\bar{X})=E(\frac{1}{n}\sum_{i=1}^{n}{X_i})=\frac{1}{n}\sum_{i=1}^{n}{E(X_i)}=\frac{1}{n}\sum_{i=1}^{n}{\mu}=\mu\]</span></p><p><span class="math display">\[\begin{align}E(S^2)&amp;=E\left[\frac{1}{n-1}\sum_{i=1}^{n}{(X_i-\bar{X})^2}\right]\\&amp;=\frac{1}{n-1}\sum_{i=1}^{n}E\left(X_i-\frac{\sum_{j=1}^{n}X_j}{n}\right)^2\\&amp;=\frac{1}{n-1}\sum_{i}E\left[X_i^2-2\frac{X_i\sum_{j}X_j}{n}+\frac{(\sum_j{X_j})^2}{n^2}\right]\\&amp;=\frac{1}{n-1}\left\{\sum_i{E(X_i^2})-E\left[\frac{(\sum_i{X_i})^2}{n}\right]\right\}\\&amp;=\frac{1}{n-1}\left[\frac{n-1}{n}\sum_i{E(X_i^2)}-\frac{1}{n}\sum_{i,j\neq i}E(X_iX_j)\right]\\\end{align}\]</span></p><p>Notice that <span class="math inline">\(X_1, X_2, ..., X_n\)</span> are independent variables, which means <span class="math inline">\(\forall i,j \in 1,\dots,n, Cov(X_i, X_j)=0\)</span>. Namely, <span class="math inline">\(E(X_iX_j)=E(X_i)E(X_j)\)</span>. So we have <span class="math display">\[\begin{align}E(S^2)&amp;=\frac{1}{n-1}\left[\frac{n-1}{n}\sum_i{E(X_i^2)}-\frac{1}{n}\sum_{i,j\neq i}E(X_i)E(X_j)\right]\\&amp;=\frac{1}{n-1}\cdot\frac{n-1}{n}\sum_i{\left[E(X_i^2)-E(X_i)^2\right]}\\&amp;=\frac{1}{n}\cdot n\operatorname{Var}(X_i)\\&amp;=\sigma^2\end{align}\]</span> It can be proved that <span class="math inline">\(S^2\)</span> and <span class="math inline">\(\bar{X}\)</span> are independent. In addition, if <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> subject to normal distribution, then <span class="math display">\[\frac{(n-1)S^2}{\sigma^2}=\frac{\sum_{i=1}^{n}{(X_i-\bar{X})^2}}{\sigma^2}\sim \chi^2(n-1)\]</span></p><h3 id="moment-generating-function">Moment Generating Function</h3><p>Consider the Taylor expansion form of exponential function <span class="math inline">\(e^{tx}\)</span> at <span class="math inline">\(x=0\)</span>, which is <span class="math display">\[e^{tx} = 1+tx+\frac{(tx)^2}{2!}+\frac{(tx)^3}{3!}+\cdots\]</span> If we replace x with random variable X, and consider the expected value of both sides, the result will be <span class="math display">\[E(e^{tX})=1+tE(X)++\frac{t^2E(X^2)}{2!}+\frac{t^3E(X^3)}{3!}+\cdots\]</span> Here, we define the moment generating function of a continuous random variable X, if it exists, to be <span class="math display">\[M(t)=E(e^{tX})=\int_{-\infty}^{+\infty}e^{tx}f(x)dx\]</span> for <span class="math inline">\(-h&lt;x&lt;h\)</span>. From the equations above, it's clearly that <span class="math display">\[M^{(r)}{(0)}=E(X^r)+\sum_{i\geq 1} a_it^i\]</span> Meanwhile, let <span class="math inline">\(S\)</span> be the set of possible values of <span class="math inline">\(X\)</span>, then <span class="math display">\[M(t)=E(e^{tX})=\sum_{x\in S}e^{tx}f(x)\]</span> Therefore, the coefficient of <span class="math inline">\(e^{tx}\)</span> is the probability: <span class="math display">\[f(x)=P(X=x)\]</span></p><h2 id="typical-discrete-distributions">Typical discrete distributions</h2><h3 id="binomial-distributions">Binomial Distributions</h3><p><span class="math inline">\(2\)</span> results, <span class="math inline">\(n\)</span> samplings. Let <span class="math inline">\(X\)</span> to be the frequency of the result with probability <span class="math inline">\(P\)</span> to be selected in a single sampling. Then we say X subjects to binomial distribution, write as <span class="math inline">\(X\sim B(n,p)\)</span>. And we have: <span class="math display">\[\begin{align}P(X=k)&amp;={n \choose k}p^{k}(1-p)^{n-k}\\E[X]&amp;=np\\\operatorname{Var}(X)&amp;=np(1-p)\end{align}\]</span></p><h3 id="poisson-distributions">Poisson Distributions</h3><p>A Poisson distribution tries to describe such a situation: an event can occur 0, 1, 2, … times in an interval. The average number of events in an interval is designated <span class="math inline">\(\lambda\)</span>. Lambda is the event rate, also called the rate parameter. Let random variable <span class="math inline">\(X\)</span> to note the number of observed events in an interval. Then we have <span class="math display">\[ P(X=k)=e^{-\lambda }{\frac {\lambda ^{k}}{k!}}\]</span> The mean and variance for Poisson distribution are both <span class="math inline">\(\lambda\)</span>. Besides, notice that <span class="math inline">\(\sum_{i}\lambda^i/i!\)</span> is the Taylor series of <span class="math inline">\(e^x\)</span> at <span class="math inline">\(x_0=0, x=\lambda\)</span>. Therefore, we can say definitely that <span class="math display">\[\sum_{k=0}^{+\infty}P(X=k)=1\]</span> In fact, Poisson distribution could be derived from binomial distribution. Suppose <span class="math inline">\(n\rightarrow +\infty\)</span> while <span class="math inline">\(np = const\)</span>. Let <span class="math inline">\(np = \lambda\)</span>, then <span class="math display">\[\begin{align}P(X=k)&amp;=\lim_{n\rightarrow +\infty}{n\choose k}p^k(1-p)^{n-k}\\&amp;=\lim_{n\rightarrow +\infty}\frac{n(n-1)\cdots(n-k+1)}{k!}\cdot\frac{\lambda^k}{n^k}(1-\frac{\lambda}{n})^{n-k}\\&amp;=e^{-\lambda}\lim_{n\rightarrow +\infty}(1-\frac{1}{n})(1-\frac{2}{n})\cdots(1-\frac{k-1}{n})\frac{\lambda^k}{k!}\\&amp;=e^{-\lambda}\frac{\lambda^k}{k!}\end{align}\]</span> With <span class="math inline">\(n\geq 20, p\leq 0.05\)</span>, the Poisson distribution can be used to approximate the binomial distribution by setting <span class="math inline">\(\lambda=np\)</span>.</p><h2 id="typical-continuous-distributions">Typical continuous distributions</h2><h3 id="uniform-distributions">Uniform Distributions</h3><p>We have introduced this kind of distributions above, here are some other properties of it. For <span class="math inline">\(a\leq x\leq b\)</span>, we have <span class="math display">\[\begin{align}F(x)&amp;=\frac{x-a}{b-a}\\\mu=E(X)&amp;=\frac{a+b}{2}\\\sigma^2=\operatorname{Var}(X)&amp;=\frac{(b-a)^2}{12}\end{align}\]</span></p><h3 id="exponential-distribution">Exponential Distribution</h3><p>The continuous random variable X follows an exponential distribution if its probability density function is: <span class="math display">\[f(x)=\frac{1}{\theta}e^{-x/\theta}~~~(x\geq0,\theta&gt;0)\]</span> For <span class="math inline">\(x\geq0,\theta&gt;0\)</span>. Besides, <span class="math display">\[\begin{align}F(x)&amp;=-e^{-x/\theta}+1\\\mu=E(X)&amp;=\theta\\\sigma^2=\operatorname{Var}(X)&amp;=\theta^2\end{align}\]</span> Here's an derivation of exponential distribution. Suppose a random event <span class="math inline">\(e\)</span> happens randomly in <span class="math inline">\(t\in [0,\infty)\)</span>, with an average frequency <span class="math inline">\(\lambda\)</span> to happen in an interval of length 1. This is to say that the number of <span class="math inline">\(e\)</span> in an interval follows Poisson distribution. Let <span class="math inline">\(X\)</span> note the distribution of the first appearance of <span class="math inline">\(e\)</span>. Then we have <span class="math display">\[\begin{align}F(X=x)&amp;=P(X\leq x)=1-P&amp;(e~happens~0~time~in~[0,x])\\&amp;=1-e^{-\lambda x}\frac{(\lambda x)^0}{0!}~~~&amp;\text{(from Poisson distribution)}\\\Rightarrow f(x)&amp;=F&#39;(x)=\lambda e^{-\lambda x}\end{align}\]</span> Let <span class="math inline">\(\theta = \frac{1}{\lambda}\)</span>, then <span class="math display">\[f(x)=\frac{1}{\theta}e^{-x/\theta}\]</span></p><h3 id="gamma-distribution">Gamma Distribution</h3><h4 id="derivation-of-gamma-distribution"><em>Derivation of Gamma Distribution</em></h4><p>Consider the derivation of exponential distribution. In the same way, we suppose a random event <span class="math inline">\(e\)</span> happens randomly in <span class="math inline">\(t\in [0,\infty)\)</span>, with an average frequency <span class="math inline">\(\lambda\)</span> to happen in an interval of length 1. However, we let <span class="math inline">\(X\)</span> note the distribution of the <span class="math inline">\(\alpha^{th}\)</span> appearance of <span class="math inline">\(e\)</span>. Then: <span class="math display">\[\begin{align}F(X=x)&amp;=P(X\leq x)=1-\sum_{i=0}^{\alpha-1}P(e~happens~i~time~in~[0,x])\\&amp;=1-\sum_{i=0}^{\alpha-1}e^{-\lambda x}\frac{(\lambda x)^i}{i!}~~~~~\text{(from Poisson distribution)}\\\Rightarrow f(x)&amp;=F&#39;(x)=\lambda e^{-\lambda x}\left\{1+\sum_{i=1}^{\alpha-1}\left[\frac{(\lambda x)^i}{i!}-\frac{(\lambda x)^{i-1}}{(i-1)!}\right]\right\}\\&amp;=\lambda^\alpha e^{-\lambda x}\cdot\frac{x^{\alpha-1}}{(\alpha-1)!}\end{align}\]</span> Let <span class="math inline">\(\theta = \frac{1}{\lambda}\)</span>, then <span class="math display">\[f(x)=\frac{1}{\theta^\alpha(\alpha-1)!}e^{-x/\theta}x^{\alpha-1}\]</span> When <span class="math inline">\(\alpha=1\)</span>, gamma distribution turns out to be exponential distribution. In the other hand, when <span class="math inline">\(\theta=2\)</span>, <span class="math inline">\(\alpha=r/2\)</span>, gamma distribution becomes Chi-square distribution.</p><p>The Gamma distribution has a mean of <span class="math inline">\(\mu=\alpha\theta\)</span> and a variance of <span class="math inline">\(\sigma^2=\alpha\theta^2\)</span>.</p><h4 id="the-gamma-function"><em>The Gamma Function</em></h4><p>The gamma function, denoted <span class="math inline">\(\Gamma(t)\)</span>, is defined, for <span class="math inline">\(t\geq 0\)</span>, by: <span class="math display">\[\Gamma(t)=\int_0^\infty y^{t-1}e^{-y}dy\]</span> Moreover, <span class="math display">\[\Gamma(t)=\frac{y^t}{t}\cdot e^{-y}\,\bigg|_0^{\infty}-\int_0^\infty\frac{y^t}{t}\cdot(-e^{-y})dy=\frac{1}{t}\Gamma(t+1)\]</span> therefore we have <span class="math inline">\(\Gamma(t+1)=t\,\Gamma(t)\)</span>.</p><p>In addition, when <span class="math inline">\(t=1\)</span>, <span class="math display">\[\Gamma(t)=\int_0^\infty e^{-y}dy=-e^{-y}\,\bigg|_0^{\infty}=1\]</span> In conclusion, for <span class="math inline">\(n\in\mathbb{N}\)</span>, <span class="math display">\[\Gamma(n)=(n-1)!\]</span></p><h4 id="chi-square-distribution"><em>Chi-square Distribution</em></h4><p>Let <span class="math inline">\(X\)</span> follow a gamma distribution with <span class="math inline">\(\theta=2\)</span> and <span class="math inline">\(\alpha=r/2\)</span>, where r is a positive integer. Then the probability density function of X will be: <span class="math display">\[f(x)=\frac{1}{2^{r/2}\Gamma(\frac{r}{2})}e^{-x/2}x^{r/2-1}(x&gt;0)\]</span> Notice that the Gamma function is the analytic continuation of the factorial function. As <span class="math inline">\(r/2\)</span> can be non-integer while <span class="math inline">\(r\)</span> is an integer, we use the Gamma function here to replace the factorial function here.</p><p>The expectation of <span class="math inline">\(\chi^2\)</span>-distribution is <span class="math inline">\(\mu=r\)</span>, while the variance is <span class="math inline">\(\sigma^2=2r\)</span>. <span class="math inline">\(r\)</span> is called degree of freedom in <span class="math inline">\(\chi^2\)</span>-distribution.</p><p>In addition, we have &gt; <strong>Theorem 1</strong>. If <span class="math inline">\(Z_1,\dots,Z_k\sim\mathcal{N}(0,1)\)</span> are independent, then the sum of their squares, &gt; <span class="math display">\[&gt; Q\ =\sum _{i=1}^{k}Z_{i}^{2}&gt; \]</span> &gt; is distributed according to the chi-squared distribution with k degrees of freedom. &gt; &gt; <strong>Theorem 2</strong>. Let <span class="math inline">\(X_i\)</span> denote <span class="math inline">\(n\)</span> independent random variables that follow these chi-square distributions, e.g., <span class="math inline">\(X_1\sim\chi^2(r_1)\)</span>, <span class="math inline">\(X_2\sim\chi^2(r_2)\)</span>, etc. Then, the sum of the random variables &gt; <span class="math display">\[&gt; Y=X_1+X_2+\cdots+X_n&gt; \]</span> &gt; follows a chi-square distribution with <span class="math inline">\(r_1+r_2+\dots+r_n\)</span> degrees of freedom. That is: &gt; <span class="math display">\[&gt; Y\sim\chi^2(r_1+r_2+\dots+r_n)&gt; \]</span></p><p>While this can be proved with <a href="https://newonlinecourses.science.psu.edu/stat414/node/72/">MGF</a>, we're not going to introduce the proof here. Just take it as a conclusion.</p><h3 id="an-interesting-story-of-betadirichlet-distribution">An interesting story of Beta/Dirichlet distribution</h3><p>See <a href="https://cosx.org/2013/01/lda-math-beta-dirichlet">here</a>.</p><h3 id="normal-distribution-or-gaussian-distribution">Normal Distribution (or Gaussian Distribution)</h3><p>The probability density function of <span class="math inline">\(\mathcal{N}(\mu, \sigma)\)</span> is <span class="math display">\[{\displaystyle f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}}\]</span> We can know from the last chapter (<em>Basic knowledge in calculus</em>) that <span class="math display">\[\int_{-\infty}^{\infty}{\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}dx} = 1\]</span> In addition, we have &gt; <strong>Theorem</strong>. Let <span class="math inline">\(X_i\)</span> denote <span class="math inline">\(n\)</span> independent random variables that follow these normal distributions. &gt; e.g., <span class="math inline">\(X_1\sim\mathcal{N}(\mu_1,\sigma_1^2)\)</span>, <span class="math inline">\(X_2\sim\mathcal{N}(\mu_2,\sigma_2^2)\)</span>, etc. Then, the linear combination &gt; <span class="math display">\[&gt; Y=c_1X_1+c_2X_2+\cdots+c_nX_n&gt; \]</span> &gt; follows the normal distribution: &gt; <span class="math display">\[&gt; Y\sim\mathcal{N}(\sum_{i=1}^nc_i\mu_i,\sum_{i=1}^nc_i^2\sigma_i^2)&gt; \]</span> &gt;</p><h4 id="z-scores"><em>Z Scores</em></h4><p>It can be proved that, for <span class="math inline">\(X\sim \mathcal{N}(0,1)\)</span>, <span class="math display">\[Z=\frac{x-\mu}{\sigma}\sim \mathcal{N}(0,1)\]</span> This formula is also the defination of Z score.</p><h4 id="relationship-of-normal-distribution-and-chi2-distribution"><em>Relationship of Normal Distribution and <span class="math inline">\(\chi^2\)</span> Distribution</em></h4><blockquote><p><strong>Theorem</strong>. If <span class="math inline">\(X\)</span> is normally distributed with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\geq 0\)</span>, then: <span class="math display">\[V=\left(\frac{X-\mu}{\sigma}\right)^2=Z^2\]</span> is distributed as a chi-square random variable with 1 degree of freedom.</p></blockquote><p>Proof: Namely it's to prove that <span class="math display">\[P(Z^2=v)=P(V=v)=g(v)=\frac{1}{\Gamma(1/2)2^{1/2}}e^{-v/2}v^{-1/2}\]</span> Meanwhile, <span class="math display">\[\begin{align}G(v)=P(Z^2\leq v)&amp;=P(-\sqrt{v}\leq Z\leq\sqrt{v})\\&amp;=\int_{-\sqrt v}^{\sqrt v}\frac{1}{\sqrt{2\pi}}e^{-x^2/2}dx\\&amp;=2\int_0^{\sqrt v}\frac{1}{\sqrt{2\pi}}e^{-x^2/2}dx\\&amp;=\int_0^{v}\frac{1}{\sqrt{2\pi}}z^{-1/2}e^{-z/2}dz\\\Rightarrow g(v)&amp;=\frac{dG(v)}{dv}=\frac{d\left(\int_0^{v}\frac{1}{\sqrt{2\pi}}z^{-1/2}e^{-z/2}dz\right)}{dv}\\&amp;=\frac{1}{\sqrt{2\pi}}v^{-1/2}e^{-v/2}\end{align}\]</span> Also, <span class="math display">\[\begin{align}\Gamma(1/2)&amp;=\int_0^\infty y^{-1/2}e^{-y}dy\\&amp;=\int_0^\infty 2e^{-u^2}du\\&amp;=\int_{-\infty}^\infty e^{-u^2}du=\sqrt{\pi}\end{align}\]</span> Therefore, <span class="math display">\[g(v)=\frac{1}{\Gamma(1/2)2^{1/2}}e^{-v/2}v^{-1/2}\]</span> Our proof is complete. Moreover, we have <span class="math display">\[\frac{(n-1)S^2}{\sigma^2}=\frac{\sum_{i=1}^{n}(X_i-\bar{X})^2}{\sigma^2}\sim\chi^2(n-1)\]</span></p><h2 id="central-limit-theorem">Central limit theorem</h2><h3 id="definition">Definition</h3><p>Let <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> be a random sample from any distribution with (finite) mean <span class="math inline">\(\mu\)</span> and (finite) variance <span class="math inline">\(\sigma^2\)</span>. If the sample size <span class="math inline">\(n\)</span> is sufficiently large, then:</p><ul><li>the sample mean <span class="math inline">\(\bar{X}\)</span> follows an approximate normal distribution</li><li>with mean <span class="math inline">\(E(\bar{X})=\mu\)</span> and variance <span class="math inline">\(Var(\bar{X})=\frac{\sigma^2}{n}\)</span></li></ul><h2 id="statistical-hypothesis-test">Statistical Hypothesis Test</h2><h3 id="about-null-hypothesis">About <em>Null Hypothesis</em></h3><p>The null hypothesis is a general statement or default position that there is no relationship between two measured phenomena, or no association among groups. Testing (trying to accept or reject) the null hypothesis — and thus concluding that there is or is not a relationship between two phenomena— is a central task in the modern practice of science.</p><p>Null Hypothesis is often denoted as <span class="math inline">\(H_0\)</span>, while the hypothesis being tested against it, also called the alternative hypothesis, is often denoted as <span class="math inline">\(H_1\)</span>. <span class="math inline">\(p\)</span> is generally used for denoting the probability of <span class="math inline">\(H_0\)</span>, namely, the probability of there's no real difference.</p><h3 id="students-t-test">Student's t-Test</h3><p>The t-test is any statistical hypothesis test in which the test statistic follows a Student's t-distribution under the null hypothesis. It was introduced in 1908 by William Sealy Gosset under his pen name "Student".</p><blockquote><p><strong>t-distribution</strong> Definition. If <span class="math inline">\(Z\sim\mathcal{N}(0,1)\)</span> and <span class="math inline">\(U\sim\chi^2(r)\)</span> are independent, then the random variable: <span class="math display">\[T=\frac{Z}{\sqrt{U/r}}\]</span> follows a t-distribution with <span class="math inline">\(r\)</span> degrees of freedom. We write <span class="math inline">\(T\sim t(r)\)</span>. The p.d.f. of <span class="math inline">\(T\)</span> is: <span class="math display">\[\frac{\Gamma \left(\frac{\nu+1}{2} \right)} {\sqrt{\nu\pi}\,\Gamma \left(\frac{\nu}{2} \right)} \left(1+\frac{x^2}{\nu} \right)^{-\frac{\nu+1}{2}}\!\]</span> It's clear that, for <span class="math inline">\(X_1,X_2,\dots,X_n\sim\mathcal{N}(\mu,\sigma^2)\)</span>, <span class="math display">\[\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\sim\mathcal{N}(0,1)\]</span> And now we have: <span class="math display">\[\frac{\bar{X}-\mu}{s/\sqrt{n}}\sim t(n-1)\]</span> where <span class="math inline">\(s\)</span> is the sample standard deviation.</p></blockquote><p>Most test statistics have the form <span class="math inline">\(t=Z/S\)</span>, where <span class="math inline">\(Z\)</span> and <span class="math inline">\(S\)</span> are functions of the data.</p><ul><li><span class="math inline">\(Z\)</span> may be sensitive to the alternative hypothesis (i.e., its magnitude tends to be larger when the alternative hypothesis is true)</li><li><span class="math inline">\(S\)</span> is a scaling parameter that allows the distribution of t to be determined.</li><li><span class="math inline">\(S^2\)</span> should follow a <span class="math inline">\(\chi^2\)</span> distribution with <span class="math inline">\(p\)</span> degrees of freedom under the null hypothesis, where <span class="math inline">\(p\)</span> is a positive constant</li></ul><h4 id="one-sample-t-test"><em>One-sample t-test</em></h4><p>Let <span class="math inline">\(Z=\bar{X}-\mu,\,S=s/\sqrt{n}\)</span>, then <span class="math display">\[{\displaystyle t={\frac {\bar{x}-\mu_{0}}{s/\sqrt {n}}}}\]</span> Note that <span class="math display">\[S^2=\frac{s^2}{n}=\sum_{i=1}^n\frac{(X_i-\bar{X})^2}{n(n-1)}\]</span></p><h4 id="two-sample-t-test"><em>Two-sample t-test</em></h4><table><colgroup><col style="width: 25%" /><col style="width: 37%" /><col style="width: 37%" /></colgroup><thead><tr class="header"><th style="text-align: center;">When to do this test</th><th style="text-align: center;"><span class="math inline">\(S\)</span></th><th style="text-align: center;">Degree of Freedom</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Small sample, <span class="math inline">\(\sigma_1^2=\sigma_2^2\)</span></td><td style="text-align: center;"><span class="math inline">\({\displaystyle \sqrt{s^2_{pool}\left(\frac{1}{n_1}+\frac{1}{n_2}\right)}}\)</span></td><td style="text-align: center;"><span class="math inline">\(n_1+n_2-2\)</span></td></tr><tr class="even"><td style="text-align: center;">Small sample, <span class="math inline">\(\sigma_1^2\neq\sigma_2^2\)</span></td><td style="text-align: center;"><span class="math inline">\({\displaystyle \sqrt{\frac{s^2_1}{n_1}+\frac{s^2_2}{n_2}}}\)</span></td><td style="text-align: center;"><span class="math inline">\({\displaystyle \left.{\left({\frac {s_{1}^{2}}{n_{1}}}+{\frac {s_{2}^{2}}{n_{2}}}\right)^{2}}\middle/\left(\frac {\left(s_{1}^{2}~/~n_{1}\right)^{2}}{n_{1}-1}+\frac {\left(s_{2}^{2}~/~n_{2}\right)^{2}}{n_{2}-1}\right)\right.}\)</span></td></tr></tbody></table><h3 id="z-test">Z-Test</h3><p>A Z-test is any statistical test for which the distribution of the test statistic under the null hypothesis can be approximated by a normal distribution. Because of the central limit theorem, many test statistics are approximately normally distributed for large samples.</p><h4 id="relationship-with-students-t-test"><em>Relationship with Student's t-Test</em></h4><p>For each significance level, the Z-test has a single critical value which makes it more convenient than the Student's t-test which has separate critical values for each sample size. Statistical tests with large sample size or known population variance can be conveniently performed as approximate Z-tests. If the population variance is unknown (and therefore has to be estimated from the sample itself) and the sample size is not large (n &lt; 30), the Student's t-test may be more appropriate.</p><h3 id="pearsons-chi-squared-test">Pearson's chi-squared test</h3><p>Pearson's chi-squared test is used to assess three types of comparison:</p><ul><li>goodness of fit</li><li>homogeneity</li><li>independence</li></ul><p>It tests a null hypothesis stating that:</p><blockquote><p>The frequency distribution of certain events observed in a sample is consistent with a particular theoretical distribution.</p></blockquote><p>The events considered must be mutually exclusive and have total probability 1.</p><h4 id="testing-for-statistical-independence"><em>Testing for statistical independence</em></h4><p>For a contingency table with <span class="math inline">\(r\)</span> rows and <span class="math inline">\(c\)</span> columns, the value of the test-statistic is</p><p><span class="math display">\[\chi ^{2}=\sum_{i=1}^{r}\sum_{j=1}^{c}{(O_{i,j}-E_{i,j})^{2}\over E_{i,j}}\]</span> in which <span class="math inline">\(O_{i,j},E_{i,j}\)</span> notes the observation and expectation in each cell, and the number of degrees of freedom <span class="math inline">\(DF=(r-1)(c-1)\)</span>.</p><h4 id="yates-correction-for-continuity"><em>Yates' Correction for Continuity</em></h4><p>The approximation to the chi-squared distribution breaks down if expected frequencies are too low.</p><ul><li>Normally the approximation is acceptable when no more than 20% of the events have expected frequencies below 5.</li><li>Where <span class="math inline">\(DF=1\)</span>, the approximation is acceptable when expected frequencies are no less than 10.</li></ul><p>In this case, a better approximation can be obtained by reducing the absolute value of each difference between observed and expected frequencies by 0.5 before squaring; this is called Yates's correction for continuity.</p><h3 id="anova">ANOVA</h3><p>ANOVA, an abbreviation of <em>Analysis of Variance</em>, is a collection of statistical models and their associated estimation procedures used to analyze the differences among group means in a sample.</p><p>In ANOVA, we generally make the following assumptions:</p><ul><li>Independence of observations – this is an assumption of the model that simplifies the statistical analysis.</li><li>Normality – the distributions of the residuals are normal.</li><li>Equality (or "homogeneity") of variances, called homoscedasticity — the variance of data in groups should be the same.</li></ul><h4 id="one-way-anova"><em>One-way ANOVA</em></h4><p>Suppose we did a research about personal annual income in several major cities, and here's the survey result:</p><table><thead><tr class="header"><th style="text-align: center;">Cities</th><th style="text-align: center;">Samples</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Beijing</td><td style="text-align: center;"><span class="math inline">\(X_{11},X_{12},X_{13},\dots\)</span></td></tr><tr class="even"><td style="text-align: center;">Shanghai</td><td style="text-align: center;"><span class="math inline">\(X_{21},X_{22},X_{23},\dots\)</span></td></tr><tr class="odd"><td style="text-align: center;">Guangzhou</td><td style="text-align: center;"><span class="math inline">\(X_{31},X_{32},X_{33},\dots\)</span></td></tr></tbody></table><p>Cities are called affect factor here. Now we want to know if there is a relationship between people's annual income and cities. For each group, assume the data obey a normal distribution <span class="math inline">\(\mathcal{N}(\mu_i, \sigma^2)\)</span>, then the null hypothesis can be: <span class="math display">\[H_0:\mu_1=\cdots=\mu_g\]</span> in which <span class="math inline">\(g\)</span> is the number of groups. Here we consider three statistics, which is:</p><ul><li>The total sum of squares, namely the variance: <span class="math display">\[S_T^2=\sum_{i=1}^{g}\sum_{j=1}^{n_i}(X_{ij}-\bar{X})^2\]</span></li><li>The intragroup sum of squares, introduced by affect factors: <span class="math display">\[S_A^2=\sum_{i=1}^{g}n_i(\bar{X_i}-\bar{X})^2\]</span></li><li>The intergroup sum of squares, introduced by stochastic error: <span class="math display">\[S_E^2=\sum_{i=1}^{g}\sum_{j=1}^{n_i}(X_{ij}-\bar{X_i})^2\]</span></li></ul><p>We can easily prove that: <span class="math display">\[S_T^2=S_A^2+S_E^2\]</span> When <span class="math inline">\(H_0\)</span> is true, we have: <span class="math display">\[S_A\sim\chi^2(g-1),S_E\sim\chi^2(n-g)\]</span> Define <span class="math inline">\(F\)</span> as the ratio of the between group variance and the within group variance, namely, <span class="math display">\[F=\frac{S_A/(g-1)}{S_E/(n-g)}\sim F(g-1,n-g)\]</span> <span class="math inline">\(F(g-1,n-g)\)</span> here means the F-distribution.</p><blockquote><p><strong>Definition of F-distribution</strong> A random variate of the F-distribution with parameters d1 and d2 arises as the ratio of two scaled chi-squared variates: <span class="math display">\[X=\frac{U_1/d_1}{U_2/d_2}\]</span> where:</p><ul><li>U1 and U2 have chi-squared distributions with d1 and d2 degrees of freedom respectively, and</li><li>U1 and U2 are independent.</li></ul></blockquote><p>Therefore, under a given significance level <span class="math inline">\(\alpha\)</span>, the rejection region is <span class="math display">\[K_0={F&gt;F_{1-\alpha}(g-1,n-g)}\]</span></p><h2 id="basic-knowledge-in-calculus">Basic knowledge in calculus</h2><p>Some basic knowledge should be introduced ahead of normal distribution, as they can be helpful to understand the distribution function of normal distribution. ### Jacobi Matrix <span class="math display">\[\mathbf {J} = {\begin{bmatrix}{\dfrac{\partial \mathbf {f} }{\partial x_{1}}} &amp;\cdots &amp;{\dfrac {\partial \mathbf {f} }{\partial x_{n}}}\end{bmatrix}}={\begin{bmatrix}{\dfrac {\partial f_{1}}{\partial x_{1}}} &amp; \cdots &amp; {\dfrac {\partial f_{1}}{\partial x_{n}}} \\\vdots &amp;\ddots &amp;\vdots \\{\dfrac {\partial f_{m}}{\partial x_{1}}} &amp; \cdots &amp; {\dfrac {\partial f_{m}}{\partial x_{n}}}\end{bmatrix}}\]</span></p><h3 id="integration-by-substitution">Integration by substitution</h3><p>Let <span class="math inline">\(x = \varphi(u)\)</span>, then we have <span class="math display">\[\begin{align}\int_{\varphi(a)}^{\varphi(b)}{f(x)}\,dx &amp;= \int_{\varphi(u)=\varphi(a)}^{\varphi(b)}{f(\varphi(u))}\,d\varphi(u)\\&amp;=\int_a^b{f(\varphi(u))\varphi&#39;(u)\,du}\end{align}\]</span> Further, let <span class="math inline">\((x, y) = (x(a, b), y(a, b))\)</span>, then <span class="math display">\[\iint_{(x,y)\in C} f(x, y)\,dx\,dy = \iint_{(x(a,b),y(a,b))\in C}{f(x(a,b), y(a,b))\big|\mathbf{J}\big|\,da\,db}\]</span> in which <span class="math inline">\(\mathbf{J} = {\begin{bmatrix} {\dfrac {\partial x}{\partial a}}&amp; {\dfrac {\partial x}{\partial b}}\\ {\dfrac {\partial y}{\partial a}}&amp; {\dfrac {\partial y}{\partial b}} \end{bmatrix}}\)</span> is the <strong>Jacobi</strong> matrix in the instance. <span class="math inline">\(\big|\mathbf{J}\big|\)</span> means the determinant of the matrix.</p><p>In particular, when replacing Cartesian coordinate system by polar coordinate system, we have <span class="math display">\[\begin{cases}    x = rcos{\theta}\\    y = rsin{\theta}\end{cases}\]</span> therefore, <span class="math display">\[\mathbf{J}=\dfrac{\partial (x,y)}{\partial (r, \theta)}={\begin{bmatrix}cos{\theta}&amp;-rsin{\theta}\&lt;span class=&quot;&quot;&gt;&lt;/span&gt;\sin{\theta}&amp;rcos{\theta}\end{bmatrix}} \Rightarrow|\mathbf{J}| = r\]</span></p><h3 id="integration-by-parts">Integration by parts</h3><p>If <span class="math inline">\(u = u(x)\)</span> and <span class="math inline">\(du = u&#39;(x)dx\)</span>, while <span class="math inline">\(v = v(x)\)</span> and <span class="math inline">\(dv = v&#39;(x)dx\)</span>, then integration by parts states that: <span class="math display">\[\begin{aligned}\int _{a}^{b}u(x)v&#39;(x)\,dx&amp;=[u(x)v(x)]_{a}^{b}-\int _{a}^{b}u&#39;(x)v(x)dx\\&amp;=u(b)v(b)-u(a)v(a)-\int _{a}^{b}u&#39;(x)v(x)\,dx\end{aligned}\]</span> or, more compactly, <span class="math display">\[\int u\,dv=uv-\int v\,du.\!\]</span></p><h3 id="kroneckers-delta">Kronecker's delta</h3><p><span class="math display">\[\delta_{i,j} = \begin{cases}    1 &amp; \text{if}~~i = j\\    0 &amp; \text{otherwise}\end{cases}\]</span></p><h3 id="intergrability-of-xne-x22">Intergrability of <span class="math inline">\(x^ne^{-x^2/2}\)</span></h3><h4 id="hermite-polynomial"><em>Hermite Polynomial</em></h4><p>For each n, define the Hermite polynomial <span class="math inline">\(H_n(x)\)</span> by <span class="math display">\[\frac{d^n}{dx^n}e^{-x^2/2}=(-1)^nH_n(x)e^{-x^2/2}\]</span> For example, <span class="math display">\[H_0(x) = 1\\\frac{d}{dx}e^{-x^2/2}=-xe^{-x^2/2}\Rightarrow H_1(x)=x\\\frac{d^2}{dx^2}e^{-x^2/2}=-e^{-x^2/2}+x^2e^{-x^2/2}\Rightarrow H_2(x)=x^2-1\\\frac{d^3}{dx^3}e^{-x^2/2}=xe^{-x^2/2}+2xe^{-x^2/2}-x^3e^{-x^2/2}\Rightarrow H_1(x)=x^3-3x\]</span></p><p>It's obvios that <span class="math inline">\(\int H_{n+1}{(x)}\,e^{-x^2/2}=-H_{n}{(x)}\,e^{-x^2/2}+C\)</span>, assume that <span class="math display">\[x^n=a_nH_n+a_{n-1}H_{n-1}+\cdots+a_0H_0\]</span> Because <span class="math inline">\(H_k(x)e^{-x^2/2}\)</span> is integrable for <span class="math inline">\(k \geq 1\)</span>, the integrability of <span class="math inline">\(x^ne^{-x^2/2}\)</span> then depends on the value of <span class="math inline">\(a_0\)</span>.</p><p>In linear algebra, <span class="math inline">\({H_0, H_1, H_2, \cdots}\)</span> form an orthogonal basis, and it has been proved that <span class="math display">\[\int_{-\infty}^{\infty} H_i(x)H_j(x)\,e^{-x^2}dx=\sqrt{2\pi}\,n!\,\delta(i, j)\]</span> Here <span class="math display">\[a_0=\frac{\left&lt;x^n, H_0\right&gt;}{\left&lt;H_0, H_0\right&gt;}=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}x^ne^{-x^2/2}dx~~\begin{cases}&gt;0&amp;n~is~even\\=0&amp;n~is~odd\end{cases}\]</span> So we can say that</p><ul><li>If n is odd, <span class="math inline">\(x^ne^{-x^2/2}\)</span> is intergrable</li><li>Otherwise, if n is even, <span class="math inline">\(x^ne^{-x^2/2}\)</span> is not intergrable</li></ul><h3 id="calculation-of-int_-inftyinfty-e-x2dx">Calculation of <span class="math inline">\(\int_{-\infty}^{\infty} e^{-x^2}dx\)</span></h3><p>Though <span class="math inline">\(H_0e^{-x^2}\)</span> is not intergrable, we can calculate the result of <span class="math inline">\(\int_{-\infty}^{\infty} e^{-x^2}dx\)</span>. Suppose the result to be <span class="math inline">\(I\)</span>. then <span class="math display">\[\begin{split}I \times I &amp;= \int_{-\infty}^{\infty}{e^{-x^2}\,dx} \times \int_{-\infty}^{\infty}{e^{-y^2}\,dy} \\ &amp;= \int_{y=-\infty}^{\infty}\int_{x=-\infty}^{\infty}{e^{-(x^2+y^2)}\,dx\,dy}\\ &amp;= \int_{\theta=-\pi}^{\pi}\int_{r=0}^{\infty}re^{-r^2}\,dr\,d\theta \\ &amp;= \int_{\theta=-\pi}^{\pi}\left(-\frac{1}{2}e^{-r^2}\right)\bigg|_{r=0}^{\infty}\,d\theta \\ &amp;= \int_{\theta=-\pi}^{\pi}{-\frac{1}{2}}\,d\theta \\ &amp;= \pi\end{split}\]</span> Apparently <span class="math inline">\(I &gt; 0\)</span>. Therefore, we have <span class="math inline">\(I = \sqrt{\pi}\)</span></p><h3 id="calculation-of-int_-inftyinftyx2ke-x2dx">Calculation of <span class="math inline">\(\int_{-\infty}^{\infty}{x^{2k}e^{-x^2}dx}\)</span></h3><p>Here we can use integration by parts.</p><p><span class="math display">\[\begin{align}\int_{-\infty}^{\infty}{x^{2k}e^{-x^2}dx}&amp;= -\frac{1}{2}\int_{-\infty}^{\infty}{x^{2k-1}\cdot\left(-2xe^{-x^2}\right)dx}\\&amp;= -\frac{1}{2}\left(x^{2k-1}e^{-x^2}\bigg|_{-\infty}^{\infty}-\int_{-\infty}^{\infty}(2k-1)x^{2k-2}e^{-x^2}dx\right)\\&amp;= \frac{2k-1}{2}\int_{-\infty}^{\infty}{x^{2k-2}e^{-x^2}dx}\\&amp;= \frac{(2k-1)!!}{2^k}\int_{-\infty}^{\infty} e^{-x^2}dx \\&amp;= \frac{(2k-1)!!}{2^k}\sqrt{\pi}\end{align}\]</span> Moreover, <span class="math display">\[{\displaystyle \int_{-\infty}^{\infty}{x^{2k}e^{-\frac{(x-a)^2}{2b^2}}dx}=(2k-1)!!\sqrt{2\pi b^{2k}}}\]</span></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Some notes I took down last summer, when I was reviewing &lt;em&gt;statistics&lt;/em&gt; and &lt;em&gt;probability&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;escape&gt;</summary>
    
    
    
    <category term="科研 / Research" scheme="https://ayllenzhang.github.io/categories/Research/"/>
    
    
    <category term="Math" scheme="https://ayllenzhang.github.io/tags/Math/"/>
    
    <category term="Probablistic" scheme="https://ayllenzhang.github.io/tags/Probablistic/"/>
    
    <category term="Note" scheme="https://ayllenzhang.github.io/tags/Note/"/>
    
  </entry>
  
  <entry>
    <title>拯救 manjaro</title>
    <link href="https://ayllenzhang.github.io/2019/07/save-manjaro/"/>
    <id>https://ayllenzhang.github.io/2019/07/save-manjaro/</id>
    <published>2019-07-16T09:27:07.000Z</published>
    <updated>2019-07-24T11:24:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>在昨晚的一次 <code>update</code> 并重启以后，Manjaro 忽然黑屏，而我旁边只有一台手机。吓得本 Newbie 当场就在 Manjaro Forum 的 <a href="https://forum.manjaro.org/c/newbies">Newbie Corner</a> 发了个<a href="https://forum.manjaro.org/t/18-04-gnome-black-screen-with-only-underscore-after-update-no-tty/94876">帖子</a>。然而发完回应者寥寥（就一个），所提的解决方法也无济于事，于是只好抱着小手机想办法。</p><p><escape><span id="more"></span></escape></p><p>情况是这样的，在显示完系统选择界面，进入 Loading 环节时，屏幕上依次列出了四行信息</p><pre class="text"><code>Loading Linux 5.0-rt-x86_64 ...Loading initial ramdisk ...mount: /sys/firmware/efi/efivars: unknown filesystem # 注：本报错此前就有Starting version 242.32-3-arch</code></pre><p>然后屏幕就定格在了黑屏，乌漆抹黑，只有左上角有一个凝固的下划线。我本来以为是更新后的初始化，结果吃了个饭回来发现还是这样，当时就惊了。更严重的是，甚至无法通过 <code>Ctrl+Alt+Fx</code> 进入 <code>tty</code> 。强制关机吧。按下关机键这个下划线还闪了两下，调皮。</p><p>玩笑归玩笑，事情还是要解决。第一个问题是如何进去。如果当时我有 MacBook Pro 在旁边的话有个很方便的解决办法，那就是 <a href="https://forum.manjaro.org/t/how-to-save-your-manjaro-installation-when-it-breaks/75">chroot</a> ，具体实现方法是制作一个 Manjaro 启动盘，在启动盘系统加载好后把原硬盘中的分区mount到系统，再用<code>chroot</code>偷天换月，然后你就可以在这个临时系统里对原系统做调整了。</p><p>但是没有，怎么办呢？我首先参考了<a href="https://www.ostechnix.com/restore-broken-arch-linux-previous-working-state/">这个网页</a>，通过在 <code>grub</code> 文件中 <code>linux</code> 为首的一行行末插入</p><div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="va">init=</span>/bin/bash</span></code></pre></div><p>从而混入了系统。</p><p>但这还远远没完，进来之后发现系统仅挂在了 <code>/</code> 一个挂载点，同时网络也无法链接，测试证明网卡也未加载。在多次试验后，我写了这么一个脚本，在每次进系统后自动完成一系列配置操作。</p><div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/bin/sh</span></span><span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span><span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 挂载各分区</span></span><span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># lsblk -f # 显示分区情况</span></span><span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">mount</span> /dev/sdb3 /boot</span><span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="fu">mount</span> /dev/sdb2 /boot/efi</span><span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="fu">mount</span> /dev/sdb5 /home</span><span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="fu">mount</span> /dev/sda1 /home/Downloads</span><span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span><span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 配置网卡</span></span><span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># lspci -v | grep Ethernet -8 # 寻找网卡模块名称，Ethernet 下 Kernal Module 后面的就是了</span></span><span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="ex">modprobe</span> e1000e # 这里我的 Module 是 e1000e</span><span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="ex">ip</span> link # 查看网卡名，其中不带 LOOPBACK 的那个是对的</span><span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="ex">ip</span> link set eth0 up # 启用网卡</span><span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="ex">dhcpcd</span> eth0 # 自动分配地址，如果失败要先 killall dhcpcd</span><span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># ping www.baidu.com -c 5 # 这个界面不加 -c 居然 Ctrl+C 停不了，第一次配完又被迫重启了...</span></span></code></pre></div><p>如此这般，看似简单，其实查了 N 个网页才查清楚上面一系列操作怎么完成。有人要说了，为什么要联网呢？因为是更新完出了错，首先要做的肯定是回滚更新。</p><div class="sourceCode" id="cb4"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span> /var/log/pacman.log <span class="kw">|</span> <span class="fu">grep</span> <span class="st">&quot;2019-07-15&quot;</span> <span class="kw">|</span> <span class="fu">grep</span> -iE <span class="st">&#39;installed|upgraded|removed&#39;</span></span></code></pre></div><p>这样就能具体看到今天 <code>pacman</code> 安装、升级、移除的包。通过 <code>grep</code> 的小技巧可以轻松回滚。</p><p>回滚完了以后系统依然无法进入，怀疑是更新导致了系统关键文件错误。由于在一开始的界面是可以更换 <code>Linux</code> 内核尝试启动的，而我尝试过后并没有效果，所以最初就排除了内核错误。而实验室的核显电脑自然也不会是因为显卡黑屏（尽管如此我还是尝试了重装驱动，无效）。所以最后能做的只有一点点翻看系统日志了。</p><div class="sourceCode" id="cb5"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ex">journalctl</span> -x -b -1 <span class="kw">|</span> <span class="fu">grep</span> -iE <span class="st">&#39;fail|error|unable&#39;</span></span><span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># -x for more information, -b -1 for the last boot</span></span></code></pre></div><p>然后翻到这么两行</p><pre class="log"><code>Jul 15 22:53:25 manjaro /usr/lib/gdm-x-session[540]: /usr/lib/Xorg: error while loading shared libraries: libnettle.so.6: cannot open shared object file: No such file or directoryJul 15 22:53:25 manjaro /usr/lib/gdm-x-session[540]: Unable to run X server</code></pre><p>这其实就很明显了。<code>X server</code> 是 Gnome 等一堆桌面环境的基础，没运行起来肯定进不了图形界面，于是搜索解决办法。解决方案非常简单，重装 <code>nettle</code> 包就行了。重装后执行</p><div class="sourceCode" id="cb7"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="bu">exec</span> /sbin/init</span></code></pre></div><p>轻松进入图形界面，收工。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在昨晚的一次 &lt;code&gt;update&lt;/code&gt; 并重启以后，Manjaro 忽然黑屏，而我旁边只有一台手机。吓得本 Newbie 当场就在 Manjaro Forum 的 &lt;a href=&quot;https://forum.manjaro.org/c/newbies&quot;&gt;Newbie Corner&lt;/a&gt; 发了个&lt;a href=&quot;https://forum.manjaro.org/t/18-04-gnome-black-screen-with-only-underscore-after-update-no-tty/94876&quot;&gt;帖子&lt;/a&gt;。然而发完回应者寥寥（就一个），所提的解决方法也无济于事，于是只好抱着小手机想办法。&lt;/p&gt;
&lt;p&gt;&lt;escape&gt;</summary>
    
    
    
    <category term="探索 / Explore" scheme="https://ayllenzhang.github.io/categories/Explore/"/>
    
    
    <category term="Manjaro" scheme="https://ayllenzhang.github.io/tags/Manjaro/"/>
    
    <category term="ArchLinux" scheme="https://ayllenzhang.github.io/tags/ArchLinux/"/>
    
  </entry>
  
  <entry>
    <title>Manjaro 装机二三事</title>
    <link href="https://ayllenzhang.github.io/2019/06/manjaro-install/"/>
    <id>https://ayllenzhang.github.io/2019/06/manjaro-install/</id>
    <published>2019-06-24T05:31:08.000Z</published>
    <updated>2019-07-24T11:24:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>作为当前 <a href="https://distrowatch.com/">DistroWatch</a> 上排名第二的 Linux 发行版，基于 ArchLinux 的 Manjaro 在共享前者的 AUR 仓库，Wiki 及社区的同时，大大简化了 ArchLinux 的上手难度。他提供丰富的图形化界面选择，自动安装驱动，且拥有专用的软件仓库，是 Linux 初学者及进阶使用者的不二选择。</p><p>网上已经有很多的 Manjaro 装机报告了，我在此加以总结，并补充上我自己遇上的一些 bug 以及解决方案。</p><p><escape><span id="more"></span></escape></p><h1 id="manjaro-的安装">Manjaro 的安装</h1><h3 id="镜像下载">镜像下载</h3><ul><li>下载地址：https://manjaro.org/download/</li><li>选择 Official（官方发行）目录下或 Community（社区发行）目录下的发行版均可</li><li>推荐初学者使用 GNOME 或 Deepin（简单易用），进阶使用者使用 KDE （美观）</li></ul><h3 id="启动盘制作工具">启动盘制作工具</h3><ul><li><p>macOS 推荐使用 <a href="https://www.balena.io/etcher/">Etcher</a></p></li><li><p>Windows 推荐使用 <a href="https://rufus.ie/">Rufus</a></p></li></ul><p>这两个都是一键配置，不像 UltraISO 有很多参数需要调。</p><h3 id="安装过程">安装过程</h3><p>注意：双系统安装需要提前分区，请参考<a href="https://blog.csdn.net/lj402159806/article/details/80218360">这个网页</a>。</p><p>一个小 Trick 是：如果你有双硬盘，建议将 <code>~/Downloads</code> 挂在机械硬盘上，然后利用 <code>ln -s</code> 建立软连接。例如，将 <code>Documents</code> 文件夹放在 <code>~/Downloads</code> 下，但通过 <code>ln -s</code> 连接到主文件夹中。这样，<code>Documents</code> 就不会占用固态硬盘的空间，而我们仍可以通过 <code>~/Documents</code> 直接访问该文件夹。</p><p>装机过程请参考<a href="https://zzycreate.github.io/2018/11/03/Manjaro的尝试/">这个网页</a>。（很有缘，博客作者和我用的同一套 Hexo 主题，只是我调了颜色）</p><h1 id="manjaro-系统配置">Manjaro 系统配置</h1><h3 id="替换国内源">替换国内源</h3><p>系统配置的第一步当然是配置软件源</p><p>在终端输入</p><div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> nano /etc/pacman.d/mirrorlist</span></code></pre></div><p>在该文件顶端添加</p><div class="sourceCode" id="cb2"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="er">Server</span> <span class="er">=</span> <span class="er">https://mirrors.tuna.tsinghua.edu.cn/archlinux/$repo/os/$arch</span></span></code></pre></div><p>然后 <code>Ctrl+O</code> 写入，<code>Ctrl+X</code> 退出。</p><p>再次在终端输入</p><div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a> <span class="fu">sudo</span> nano /etc/pacman.conf</span></code></pre></div><p>在文件末端加上</p><div class="sourceCode" id="cb4"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ot">[</span><span class="er">archlinuxcn</span><span class="ot">]</span></span><span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="er">Server</span> <span class="er">=</span> <span class="er">https://mirrors.tuna.tsinghua.edu.cn/archlinuxcn/$arch</span></span></code></pre></div><p>同理保存退出</p><p>终端输入如下指令更新软件源：</p><div class="sourceCode" id="cb5"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> pacman -Syy <span class="kw">&amp;&amp;</span> <span class="fu">sudo</span> pacman -S archlinuxcn-keyring</span></code></pre></div><h3 id="安装-yay-并配置">安装 <code>yay</code> 并配置</h3><p>安装方式：终端输入如下代码</p><div class="sourceCode" id="cb6"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone https://aur.archlinux.org/yay.git</span><span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> yay</span><span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="ex">makepkg</span> -si</span></code></pre></div><p>同样，将软件源修改为清华源提速：</p><div class="sourceCode" id="cb7"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">yay</span> --aururl <span class="st">&quot;https://aur.tuna.tsinghua.edu.cn&quot;</span> --save</span></code></pre></div><h3 id="安装输入法">安装输入法</h3><p><del>此处采用<code>fcitx + sogoupinyin</code> 的安装方案</del></p><p><code>sogoupinyin</code>实在是 bug 太多了，换用<code>fcitx + cloudpinyin</code> 的安装方案</p><div class="sourceCode" id="cb8"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> pacman -S fcitx-im fcitx-configtool</span><span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> pacman -S fcitx-gtk2 fcitx-gtk3 fcitx-qt4 fcitx-qt5 <span class="co"># 都装全少点问题</span></span><span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> pacman -S fcitx-googlepinyin fcitx-cloudpinyin</span></code></pre></div><p>编辑 ~/.xprofile 和 /etc/profile，加入（两个文件都要加入）</p><div class="sourceCode" id="cb9"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="er">export</span> <span class="er">GTK_IM_MODULE=fcitx</span></span><span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="er">export</span> <span class="er">QT_IM_MODULE=fcitx</span></span><span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="er">export</span> <span class="er">XMODIFIERS=&quot;@im=fcitx&quot;</span></span></code></pre></div><p>如果依然无法使用，在 <code>~/.profile</code> 也加一份，并在 <code>~/.xinitrc</code> 中加入 <code>fcitx &amp;</code>。</p><p>其他解决方法参考 <a href="https://forum.ubuntu.org.cn/viewtopic.php?t=480390">here</a></p><h3 id="安装-git-并配置-ssh">安装 Git 并配置 ssh</h3><div class="sourceCode" id="cb10"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> pacman -S git</span><span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> config --global user.name <span class="op">&lt;</span>your_name<span class="op">&gt;</span></span><span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> config --global user.email <span class="op">&lt;</span>your_email<span class="op">&gt;</span></span><span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ~/.ssh</span><span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ssh-keygen</span> -t rsa -C <span class="st">&quot;&lt;your_email&gt;&quot;</span> <span class="co"># 然后回车两次，如果不需要 passphrase 的话</span></span><span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="bu">eval</span> <span class="st">&quot;</span><span class="va">$(</span><span class="fu">ssh-agent</span> -s<span class="va">)</span><span class="st">&quot;</span> <span class="co"># 后台启动 ssh-agent</span></span><span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ssh-add</span> ~/.ssh/id-rsa</span><span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> pacman -S xclip</span><span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="ex">xclip</span> -sel clip <span class="op">&lt;</span> ~/.ssh/id_rsa.pub # 此行指令将公钥复制到剪切板，粘贴到 Github 上添加即可</span></code></pre></div><h3 id="其他软件安装">其他软件安装</h3><h4 id="安装-chrome-及-node.js">安装 Chrome 及 node.js</h4><div class="sourceCode" id="cb11"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> pacman -S google-chrome nodejs npm</span></code></pre></div><h4 id="安装截图软件-deepin-screenshot">安装截图软件 <code>deepin-screenshot</code></h4><div class="sourceCode" id="cb12"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> pacman -S deepin-screenshot</span></code></pre></div><h4 id="安装-vscode">安装 VSCode</h4><div class="sourceCode" id="cb13"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> pacman -S visual-studio-code-bin</span></code></pre></div><h4 id="安装-qqtim-和-wechat">安装 QQ，TIM 和 WeChat</h4><div class="sourceCode" id="cb14"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> pacman -S deepin.com.qq.office</span><span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> pacman -S deepin.com.qq.im</span><span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> pacman -S electronic-wechat-git</span></code></pre></div><h4 id="安装-福昕阅读器网易云smplayergoldendict">安装 福昕阅读器，网易云，smplayer，goldendict</h4><div class="sourceCode" id="cb15"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="ex">yay</span> -S foxitreader netease-cloud-music smplayer goldendict </span></code></pre></div><p>注意 <code>yay</code> 不要加 <code>sudo</code></p><p>goldendict 需要手动添加词典，<a href="https://github.com/skywind3000/ECDICT/wiki">下载地址</a></p><h5 id="选装typora一款轻便好用的-markdown-编辑器支持所见即所得我用这个写的博客">（选装）Typora：一款轻便好用的 markdown 编辑器，支持所见即所得（我用这个写的博客）</h5><div class="sourceCode" id="cb16"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="ex">yay</span> -s typora</span></code></pre></div><h4 id="安装字体">安装字体</h4><div class="sourceCode" id="cb17"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 文泉驿</span></span><span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="ex">yay</span> -S wqy-microhei-lite</span><span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="ex">yay</span> -S wqy-bitmapfont </span><span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="ex">yay</span> -S wqy-zenhei</span><span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Adobe 系列</span></span><span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="ex">yay</span> -S adobe-source-han-sans-cn-fonts </span><span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="ex">yay</span> -S adobe-source-han-serif-cn-fonts </span><span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="ex">yay</span> -S noto-fonts-cjk</span></code></pre></div><h4 id="安装-ss-ssr">安装 SS / SSR</h4><h5 id="ss-安装">SS 安装</h5><div class="sourceCode" id="cb18"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> pacman -S shadowsocks-qt5</span></code></pre></div><h5 id="ssr-安装">SSR 安装</h5><div class="sourceCode" id="cb19"><pre class="sourceCode html"><code class="sourceCode html"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a># GFW 导致直接 yay -S electron-ssr 会失效</span><span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a># 请直接到此处下载 pacman 包</span><span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>https://github.com/qingshuisiyuan/electron-ssr-backup/releases</span><span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a># 如果 SSR 安装异常请先安装 gconf</span></code></pre></div><h5 id="tweaks-安装">Tweaks 安装</h5><p>Gnome Tweaks 是 Gnome 下的一款主题管理软件</p><div class="sourceCode" id="cb20"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> pacman -S gnome-tweak-tool</span></code></pre></div><h3 id="其他配置">其他配置</h3><h4 id="配置快捷键">配置快捷键</h4><p>设置-设备-键盘-下划到最下方点击 <code>+</code> 号新建快捷键，自行设定即可，命令为要打开的软件名</p><h4 id="文件夹默认打开方式出错解决方法例如默认文件夹打开方式变为vscode">文件夹默认打开方式出错解决方法（例如默认文件夹打开方式变为VSCode）</h4><p>设置-应用-移除相应误开软件的文件打开方式绑定</p><h4 id="配置主题后报错-gtk-warning-...-theme-parsing-error">配置主题后报错 <code>Gtk-WARNING **: ... :Theme parsing error</code></h4><p>在终端中输入</p><div class="sourceCode" id="cb21"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> /usr/share/themes/</span><span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ls</span></span></code></pre></div><p>找到你当前主题对应的文件夹（不清楚主题名称可在 Tweaks 中查看）</p><p>然后进入其下的 <code>gtk-&lt;version&gt;</code> 文件夹，<code>&lt;version&gt;</code> 对应你当前的GTK版本，大概率是其中的最新版。</p><p>然后根据报错信息手动修改文件夹中的 <code>gtk.css</code> 即可。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;作为当前 &lt;a href=&quot;https://distrowatch.com/&quot;&gt;DistroWatch&lt;/a&gt; 上排名第二的 Linux 发行版，基于 ArchLinux 的 Manjaro 在共享前者的 AUR 仓库，Wiki 及社区的同时，大大简化了 ArchLinux 的上手难度。他提供丰富的图形化界面选择，自动安装驱动，且拥有专用的软件仓库，是 Linux 初学者及进阶使用者的不二选择。&lt;/p&gt;
&lt;p&gt;网上已经有很多的 Manjaro 装机报告了，我在此加以总结，并补充上我自己遇上的一些 bug 以及解决方案。&lt;/p&gt;
&lt;p&gt;&lt;escape&gt;</summary>
    
    
    
    <category term="探索 / Explore" scheme="https://ayllenzhang.github.io/categories/Explore/"/>
    
    
    <category term="manjaro" scheme="https://ayllenzhang.github.io/tags/manjaro/"/>
    
    <category term="linux" scheme="https://ayllenzhang.github.io/tags/linux/"/>
    
    <category term="installation" scheme="https://ayllenzhang.github.io/tags/installation/"/>
    
  </entry>
  
  <entry>
    <title>儿时的火车记忆</title>
    <link href="https://ayllenzhang.github.io/2019/06/train-memory/"/>
    <id>https://ayllenzhang.github.io/2019/06/train-memory/</id>
    <published>2019-05-31T18:25:14.000Z</published>
    <updated>2021-06-19T17:41:09.551Z</updated>
    
    <content type="html"><![CDATA[<p>已经是2019年的儿童节了。十几年过去，童年时代的记忆早已被冲洗的很淡很淡，以至于我每次回想都有种在用恢复工具恢复误删照片的感觉——其中一些就是不见了，仿佛从未存在过，而另一些可能已经被其他文件痕迹所污染，辨不分明。但关于火车的记忆文件却从未消逝，反而在一次次访问时在脑内留下越来越深的痕迹。于是想着或许可以写些东西来纪念它们。</p><p><escape><span id="more"></span></escape></p><p>十几年前，奥运到来之前，安检还仅仅存在于机场——至少在长沙这样的南方小城是这样。那时的入站颇有些大礼堂学生节入场的感觉，也许是因为都有着狭长的门厅与鹅黄色的灯光。走过漆痕斑驳的检票通道，就到了车站大厅。大堂正中央宽而慢的台阶连接着一楼与二楼，两层左右各有两个候车室，此刻倒又像是图书馆了。一楼候车室的尽头直连着一站台，那是长沙站最高贵的站台，毕竟在那个没有电梯的年代里全程不走楼梯进出站也算是种享受。通常，只有北京抵长的Z17有资格停靠，再不济也得是T20以内的车辆。另一个高贵的站台是4站台，作为曾经长沙站唯一的高站台，它通常是两列进京特快Z18/T2的出发站台。4站台是最西的站台，远端是远离城市喧嚣的树林与城郊风光。六点半发车的Z18往往会在落日与晚霞交相辉映之时拉响她悠长的汽笛，洗的透亮的银色的车顶映着霞光，向北缓缓驶去，高傲而美丽。</p><p><img src="https://i.loli.net/2021/06/19/cyk8pDUIjzEAlZ2.png" alt="train_plat.png" /> &gt; 上图为Z18使用的25T客车。一直认为这是国内最好看的客车车厢涂装，没有之一。可惜的是13年开始铁道部逐步开展了普速客车统型工作，现在早已是全国一片绿了。</p><p>坐的最多的要数去往湘西老家的红皮车。在湘西的山水隧桥间奔行的它，140的速度感觉上甚至比京广线上蓝皮的160还要快。除了春节，我爸有段时间负责老家的项目，每月往返于长沙与湘西，同样是乘坐那趟列车。我妈和我每次都会去买好站台票送他。3站台，九点发车，旁边停着的是另一辆橙皮——长沙至福州的1681次。两辆车在平日里都没有太多旅客，站台上很安静，旁边只有扶着手扶车小睡的小摊贩与偶尔路过的保洁员。大概是因为去的太多，火车司机偶尔会领我去驾驶室玩玩，让我拉响汽笛，然后送我下车，招手。画面像是老照片一样定格在那儿。 后来去了北京旅游，第一次坐了z18，当时的感受放现在应该类似于第一次坐头等舱飞纽约。第一次见到带真空集便器的干净厕所，车厢也很整洁，玻璃仿佛都别擦拭得亮一些，一切都很美好。开车前列车员会一遍遍提醒亲属及时下车，当年的直达还是真正的直达，没有任何中间停站，上错车就只能等到北京再下了。我还记得那天是满月，八年后我去学校报到还是同一趟车，还是满月。相同的还有这两次我都在循环着《当时的月亮》入睡，尽管用着的是不同的播放器，心态也大相径庭了。说起来北京站帮我解释了一个我小时候一直疑惑的问题：铁路线的尽头是什么样子？然后发现火车站就变成了火车栈（真实程序员笑话）。当然现在北京站和北京西修了地下联络线，已经不再是北京栈了。</p><figure><img src="https://i.loli.net/2021/06/18/aUGYAQv8cLWronj.png" alt="beijing_north.png" /><figcaption aria-hidden="true">beijing_north.png</figcaption></figure><blockquote><p>图为此前的北京北站（栈），目前正在为迎接冬奥会而大改造中。</p></blockquote><p>卧铺有着它独有的美好。作为从小睡眠困难的人，列车哐当哐当的响声是最好的催眠剂。与其说是车轮与铁轨敲响的简单节奏，不如说已经是是种令人心安的旋律了，想来可能和听着郭德纲和于谦的相声睡觉一个原理。想想那是车轮在铁轨连接处”跳跃”所发出的声音，好像还挺可爱的。然而除却呼噜声与体味之外，还有一不好之处。京广线上最漂亮的风景要数黄鹤楼与武汉长江大桥，铁路就修在黄鹤楼一墙之隔的地方，无论是从车上看游客还是从黄鹤楼里拍车都是很棒的体验。但如果坐卧铺回北京，就必然晚上经过这儿，从而看不到什么风景了。值得一提的事，作为一个老手，平日挑选车次不单看出发时间和运行时长，在白天经过风景路段同样会成为车次的加分项。 再后来，十四岁的时候，一个人去了甘肃旅行。兰州站挂着很多三角小彩旗，站台是很经典的蓝白配色。五年后我又去了一次，尽管只是路过，但意外的发现当年的小摊还在，旗子换成了方的但还是很好看。只是后面已然起了高楼，见不着山景了。说起小摊，又想起从桂林回来的路上，本来不饿，看到老太太很晚还在站台上卖东西就买了一盒方便面，泡完发现过期了...</p><figure><img src="https://i.loli.net/2021/06/19/ogIvL3heXxcaQEy.jpg" alt="lanzhou.jpg" /><figcaption aria-hidden="true">lanzhou.jpg</figcaption></figure><p>总之还有很多很多值得一谈的趣事，比如期待了几年才坐上最后却发现不过如此的双层火车，比如长沙到茶陵那趟连新开铺都停的五位数编号普快，比如在不坐火车的日子里经常会去看车的铁路桥以及桥下的岗亭，不是每趟车都会让守路员敬礼。但是也就随便闲聊，下次有缘再说吧。 去了那么多地方，也见了各种各样的风景，我却总是对那些夜里从火车上醒来的瞬间印象特别深。我记得夜色中皎洁月光照耀下的京广线，记得云中的朦胧月色洒在青藏高原上，记得沙丘远方天空将将泛起的鱼肚白，我想我是执着地爱着这种感觉的，或许是因为它与人生或多或少的相似之处。景色的精彩是人生的一部分，而大多数日子里我们却只是在被时间载着向不确定的远方行去。过去的日子如同一场大梦，醒来又不知身在何方，身边尽是寂静，想倾诉又不忍打扰他人的安宁，只听见车轮滚动如时间逝去的声音。 在这样的时候，能遇到恰好同时醒来的某人，相视一笑，然后轻轻聊些只有你们会聊的话题，是多么幸运的事。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;已经是2019年的儿童节了。十几年过去，童年时代的记忆早已被冲洗的很淡很淡，以至于我每次回想都有种在用恢复工具恢复误删照片的感觉——其中一些就是不见了，仿佛从未存在过，而另一些可能已经被其他文件痕迹所污染，辨不分明。但关于火车的记忆文件却从未消逝，反而在一次次访问时在脑内留下越来越深的痕迹。于是想着或许可以写些东西来纪念它们。&lt;/p&gt;
&lt;p&gt;&lt;escape&gt;</summary>
    
    
    
    <category term="印象 / Impression" scheme="https://ayllenzhang.github.io/categories/Impression/"/>
    
    
    <category term="Train" scheme="https://ayllenzhang.github.io/tags/Train/"/>
    
  </entry>
  
</feed>
